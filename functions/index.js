const functions = require('firebase-functions');
const admin = require('firebase-admin');
const { OpenAI } = require('openai');
const { TextToSpeechClient } = require('@google-cloud/text-to-speech');

admin.initializeApp();

// Initialize OpenAI only when function is called
function getOpenAI() {
  return new OpenAI({
    apiKey: functions.config().openai.key
  });
}

// Helper: Get system mode
function getSystemMode(modeId) {
  const systemModes = {
    'timelapse_build': {
      name: { th: 'Time-lapse à¸ªà¸£à¹‰à¸²à¸‡à¸šà¹‰à¸²à¸™', en: 'Time-lapse Build', zh: 'å»¶æ—¶å»ºé€ ' },
      sceneBlueprint: [
        { order: 1, description: 'Foundation', duration: 10 },
        { order: 2, description: 'Frame construction', duration: 10 },
        { order: 3, description: 'Completed house', duration: 10 }
      ]
    }
    // Add more system modes here
  };
  return systemModes[modeId];
}

// Function: Generate Prompts (Auth Required)
exports.generatePrompts = functions
  .runWith({ secrets: ['OPENAI_API_KEY'] })
  .https.onCall(async (data, context) => {
    // Check authentication
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }
    const { projectId, modeId } = data;
    const userId = context.auth.uid;

    try {
      // Get project data
      const projectDoc = await admin.firestore()
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .get();

      if (!projectDoc.exists) {
        throw new functions.https.HttpsError('not-found', 'Project not found');
      }

      const project = projectDoc.data();

      // Get mode data
      let mode;
      if (project.modeType === 'system') {
        mode = getSystemMode(modeId);
      } else if (project.modeType === 'custom') {
        const modeDoc = await admin.firestore()
          .collection('users').doc(userId)
          .collection('customModes').doc(modeId)
          .get();
        mode = modeDoc.data();
      } else if (project.modeType === 'marketplace') {
        const modeDoc = await admin.firestore()
          .collection('marketplaceModes').doc(modeId)
          .get();
        mode = modeDoc.data().mode;
      }

      if (!mode) {
        throw new functions.https.HttpsError('not-found', 'Mode not found');
      }

      // Call OpenAI
      const openai = new OpenAI({ apiKey: functions.config().openai.key });
      const response = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'You are a video content planner. Generate detailed scene prompts for AI video generation. Return JSON only.'
          },
          {
            role: 'user',
            content: JSON.stringify({
              concept: project.concept,
              scenes: project.scenes,
              aspect: project.aspect,
              modeBlueprint: mode.sceneBlueprint
            })
          }
        ],
        temperature: 0.7,
        max_tokens: 2000
      });

      let content = response.choices[0].message.content;
      // Basic cleanup if markdown backticks are included
      content = content.replace(/```json/g, '').replace(/```/g, '').trim();

      const result = JSON.parse(content);
      return {
        prompts: result.prompts,
        caption: result.caption,
        hashtags: result.hashtags
      };
    } catch (error) {
      console.error('Error generating prompts:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// Function: Reset Daily Post Counts (Scheduled 00:00 BKK)
exports.resetDailyPostCounts = functions.pubsub.schedule('0 0 * * *')
  .timeZone('Asia/Bangkok')
  .onRun(async (context) => {
    const batch = admin.firestore().batch();
    const usersSnapshot = await admin.firestore().collection('users').get();

    for (const userDoc of usersSnapshot.docs) {
      const accountsSnapshot = await admin.firestore()
        .collection('users').doc(userDoc.id)
        .collection('accounts').get();

      for (const accountDoc of accountsSnapshot.docs) {
        batch.update(accountDoc.ref, { postsToday: 0 });
      }
    }

    await batch.commit();
    console.log('Daily post counts reset');
  });

// Function: Seed Database (HTTP Utility)
exports.seedDatabase = functions.https.onRequest(async (req, res) => {
  try {
    const userId = 'user_demo_123';
    const batch = admin.firestore().batch();

    // 1. Create User
    const userRef = admin.firestore().collection('users').doc(userId);
    batch.set(userRef, {
      email: 'demo@example.com',
      displayName: 'Demo User',
      role: 'admin',
      subscription: {
        plan: 'pro',
        status: 'active',
        currentPeriodEnd: admin.firestore.FieldValue.serverTimestamp()
      },
      language: 'th',
      createdAt: admin.firestore.FieldValue.serverTimestamp()
    }, { merge: true });

    // 2. Create Account
    const accountRef = userRef.collection('accounts').doc('youtube_main');
    batch.set(accountRef, {
      platform: 'youtube',
      accountName: 'My Channel',
      profilePath: '',
      dailyPostLimit: 20,
      minIntervalMinutes: 20,
      postsToday: 0,
      lastPostTime: 0,
      status: 'active',
      createdAt: admin.firestore.FieldValue.serverTimestamp()
    }, { merge: true });

    // 3. Create Project
    const projectRef = userRef.collection('projects').doc('project_demo');
    batch.set(projectRef, {
      name: 'Demo Project',
      concept: 'Architecture',
      scenes: 3,
      aspect: '9:16',
      modeType: 'system',
      modeId: 'timelapse_build',
      status: 'active',
      createdAt: admin.firestore.FieldValue.serverTimestamp()
    }, { merge: true });

    // 4. Create Timeslot
    const date = new Date().toISOString().split('T')[0];
    const timeslotRef = admin.firestore().collection('timeslots').doc(`${date}_${userId}`);
    batch.set(timeslotRef, {
      date: date,
      userId: userId,
      slots: []
    }, { merge: true });

    // 5. Create Marketplace Mode
    const marketModeRef = admin.firestore().collection('marketplaceModes').doc('mode_demo');
    batch.set(marketModeRef, {
      creatorId: userId,
      creatorName: 'Admin',
      price: 0,
      publishedAt: admin.firestore.FieldValue.serverTimestamp()
    }, { merge: true });

    await batch.commit();
    res.json({ success: true, message: 'Database seeded successfully' });
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: error.message });
  }
});

// Function: Generate Speech (Secure TTS Proxy)
exports.generateSpeech = functions
  .runWith({ secrets: [] }) // Note: TTS usually uses default credentials if enabled in GCP
  .https.onCall(async (data, context) => {
    // Check authentication
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }

    const { text, voiceParams } = data;
    if (!text) {
      throw new functions.https.HttpsError('invalid-argument', 'Text is required');
    }

    try {
      const client = new TextToSpeechClient();
      const request = {
        input: data.ssml ? { ssml: data.ssml } : { text: text },
        voice: voiceParams || { languageCode: 'en-US', name: 'en-US-Chirp3-HD-Charon' },
        audioConfig: {
          audioEncoding: 'MP3'
        },
      };

      const [response] = await client.synthesizeSpeech(request);
      return { audioContent: response.audioContent.toString('base64') };
    } catch (error) {
      console.error('Error generating speech:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// Helper: Normalize Percentages (Auto-Correction)
function normalizePercentages(items) {
  if (!items || items.length === 0) return [];

  let total = 0;
  // 1. Initial Pass: Parse integers
  items.forEach(item => {
    item.percentage = parseInt(item.percentage) || 0;
    total += item.percentage;
  });

  // 2. Safety Valve: If total is 0 or wildly invalid (e.g. > 110 or < 90), reset to equal distribution
  // We use a loose threshold to allow minor user errors to be fixed by math, but major ones get a hard reset.
  if (total < 90 || total > 110) {
    const split = Math.floor(100 / items.length);
    let remainder = 100 - (split * items.length);

    items.forEach(item => {
      item.percentage = split;
      if (remainder > 0) {
        item.percentage += 1;
        remainder--;
      }
    });
  } else {
    // 3. Precise Adjustment: If close to 100 (e.g. 99 or 101), just fix the last item
    if (total !== 100) {
      const diff = 100 - total;
      items[items.length - 1].percentage += diff;
    }
  }

  return items;
}

// Function: Analyze Mode (AI Critique + TTS)
exports.analyzeMode = functions
  .runWith({ secrets: [], timeoutSeconds: 300, memory: '1GB' }) // Fix Timeout & Memory for heavy AI tasks
  .https.onCall(async (data, context) => {
    // Check authentication
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }

    // Support both direct object (if called directly) or nested via Callable .data
    const input = data.modeData || (data.data && data.data.modeData) || data;
    let { name, description, category, systemInstruction, variables, blocks } = input;

    // *If input is still just a prompt string (legacy fallback), handle it?*
    // Ideally we force the frontend to send the object now. But let's check.
    if (!blocks && data.promptText) {
      // Fallback for direct promptText calls (Legacy) - Just wrap it
      console.log("âš ï¸ Legacy promptText received. Bypassing percentage logic.");
      // We can't do percentage logic here, so strictly we should just proceed or fail.
      // Let's assume for this task we are moving to structured data.
    }

    // 1. Backend Normalization (Auto-Correct Logic)
    if (blocks && Array.isArray(blocks)) {
      // Level 1: Sequences
      blocks = normalizePercentages(blocks);

      // Level 2: Steps within Sequences
      blocks.forEach(block => {
        if (block.evolution && Array.isArray(block.evolution)) {
          block.evolution = normalizePercentages(block.evolution);
        }
      });
    }

    try {
      // 2. Construct Prompt from Structured Data (NEW: No rawPrompt - only block titles)
      let structureText = "";
      if (blocks) {
        blocks.forEach((block, i) => {
          const seqPercent = block.sequencePercentage || block.percentage || 0;
          structureText += `Scene ${i + 1}: ${block.title} (${seqPercent}%)\n`;
          // Note: evolution/steps still exist for timing but no rawPrompt
          if (block.evolution && block.evolution.length > 1) {
            block.evolution.forEach((step, j) => {
              const stepPercent = step.stepPercentage || step.percentage || 0;
              structureText += `  - Step ${j + 1}: [${stepPercent}% of scene time]\n`;
            });
          }
        });
      }

      const fullPrompt = `
      Title: ${name}
      Category: ${category || 'Cinematic / Movie'}
      Description: ${description}
      Instruction: ${systemInstruction}
      Variables: ${variables ? variables.map(v => v.name).join(', ') : 'None'}
      
      Blueprint / Timeline:
      ${structureText}
      
      User Original Prompt (Legacy): ${data.promptText || ''}
      `.trim();

      console.log("Normalized Payload:", JSON.stringify(blocks, null, 2));

      // 3. AI Analysis
      const openai = getOpenAI();
      const completion = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `You are Charon, a world-class AI Mode Architect Critic.
            Speak Thai. CRITICAL RULE: You MUST use punctuation to control the audio flow for Google TTS.
            
            Analyze the user's Mode Blueprint. This is a TEMPLATE for video generation.
            
            [ðŸŽ¯ WHAT YOU ARE ANALYZING]
            - Mode = Template with scene titles (NOT full scripts)
            - Scene titles use [TOPIC] placeholder (will be replaced by Content Queue later)
            - Expander system will add cinematic details later
            - Focus on: STRUCTURE, PACING, SCENE FLOW
            
            [DYNAMIC PERSONA: WORLD-CLASS STRUCTURE CRITIC]
            You are a Visionary Producer critiquing the TEMPLATE DESIGN:
            - SCORE 0-4: Poor structure, confusing flow, bad pacing
            - SCORE 5-7: Decent structure, room for improvement
            - SCORE 8-10: Excellent narrative arc, perfect pacing

            [TTS FORMATTING RULES - CRITICAL]
            - DO NOT USE DIGITS (0-9). SPELL OUT ALL NUMBERS IN THAI.
            - Example: "80%" -> "à¹à¸›à¸”à¸ªà¸´à¸šà¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œ"

            [WHAT TO CRITIQUE]
            1. Scene count - à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸¥à¹ˆà¸²à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ?
            2. Scene titles - à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸¡à¸µà¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ?
            3. Percentage allocation - à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¹€à¸§à¸¥à¸²à¸ªà¸¡à¹€à¸«à¸•à¸¸à¸ªà¸¡à¸œà¸¥à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ?
            4. Narrative arc - à¸¡à¸µ Hook, Rising Action, Climax à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ?
            5. System Instruction - à¸Šà¸±à¸”à¹€à¸ˆà¸™à¸žà¸­à¹ƒà¸«à¹‰ AI à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ?

            MANDATORY SECTION: "ðŸš‘ à¸„à¸³à¹à¸™à¸°à¸™à¸³:"
            - à¸ˆà¸³à¸™à¸§à¸™à¸‰à¸²à¸à¸—à¸µà¹ˆà¹à¸™à¸°à¸™à¸³
            - à¸›à¸£à¸±à¸šà¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¹€à¸§à¸¥à¸²à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£
            - à¸Šà¸·à¹ˆà¸­à¸‰à¸²à¸à¸—à¸µà¹ˆà¸„à¸§à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™
            
            Output a JSON object:
            {
              "score": integer (0-10),
              "script": "..."
            }
            CRITICAL: Output strictly VALID JSON. MINIFY (single line). Use literal '\\n' for newlines.
            `
          },
          {
            role: 'user',
            content: `Analyze this Mode: ${fullPrompt}`
          }
        ],
        temperature: 0.7,
      });

      let content = completion.choices[0].message.content;

      // 1. Remove Markdown Wrappers
      content = content.replace(/```json/g, '').replace(/```/g, '').trim();

      // 2. Extract strictly from first '{' to last '}'
      const firstBrace = content.indexOf('{');
      const lastBrace = content.lastIndexOf('}');
      if (firstBrace !== -1 && lastBrace !== -1) {
        content = content.substring(firstBrace, lastBrace + 1);
      }

      // 3. DEBUG LOGGING (CRITICAL)
      console.log("CLEANED_JSON_PAYLOAD:", content);

      const result = JSON.parse(content);

      // 2. Generate Speech for the Script (CHUNKED to avoid limit)
      const ttsClient = new TextToSpeechClient();
      const chunks = chunkText(result.script, 180); // Smart Splitter (limit 180)
      const audioBuffers = [];

      for (const chunk of chunks) {
        if (!chunk.trim()) continue;
        const ttsRequest = {
          input: { text: chunk },
          voice: { languageCode: 'en-US', name: 'en-US-Chirp3-HD-Charon' },
          audioConfig: { audioEncoding: 'MP3' },
        };
        const [response] = await ttsClient.synthesizeSpeech(ttsRequest);
        if (response.audioContent) {
          audioBuffers.push(response.audioContent);
        }
      }

      // Concatenate all audio buffers
      const finalAudio = Buffer.concat(audioBuffers);

      return {
        score: parseInt(result.score) || 0, // Enforce Integer
        script: result.script,
        audioContent: finalAudio.toString('base64')
      };

    } catch (error) {
      console.error('Error analyzing mode:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// --- HELPER: Text Chunking ---
// --- HELPER: Smart Splitter for Lossless TTS ---
function chunkText(text, maxLength) {
  if (!text) return [];

  const chunks = [];
  let remaining = text;

  while (remaining.length > maxLength) {
    // Priority 1: Split at last Punctuation within limit
    // We look for . ! ? or newline
    let splitIndex = -1;
    const punctuationRegex = /[.!?\n]/;

    // Search backwards from limit
    for (let i = maxLength; i >= 0; i--) {
      if (punctuationRegex.test(remaining[i])) {
        splitIndex = i + 1; // Include the punctuation
        break;
      }
    }

    // Priority 2: Split at last Space within limit (if no punctuation found)
    if (splitIndex === -1) {
      splitIndex = remaining.lastIndexOf(' ', maxLength);
      if (splitIndex !== -1) splitIndex += 1; // Include space (or split after it)
    }

    // Priority 3: Hard limit (Force split)
    if (splitIndex === -1) {
      splitIndex = maxLength;
    }

    // Extract chunk
    const chunk = remaining.substring(0, splitIndex).trim();
    if (chunk) chunks.push(chunk);

    // Update remaining text
    remaining = remaining.substring(splitIndex).trim();
  }

  // Add the last piece
  if (remaining) chunks.push(remaining);

  return chunks;
}

// --- 3. Mode Architect (Consultant) - AI Story Director ---

// ============================================
// SHARED HELPER: Per-Scene Expansion with Episode Topic
// Used by: testPromptPipeline, scheduleJobs
// This ensures Generate Test and Production use IDENTICAL logic
// ============================================
async function expandScenesWithTopic(params) {
  const {
    rawScenes,          // Array of scene objects from Mode
    expanderBlocks,     // Array of Expander rule blocks
    episodeTopic,       // Episode title (main topic)
    episodeDesc,        // Episode description
    characters,         // Array of character objects
    sceneDuration = 8,  // Duration per scene (seconds)
    modeCategory,       // Mode category (Cinematic, etc.)
    systemInstruction   // Mode-level system instruction
  } = params;

  const openai = getOpenAI();
  const expandedPrompts = [];

  // Build Expander block instructions
  const blockInstructions = expanderBlocks && expanderBlocks.length > 0
    ? expanderBlocks.map((b, i) => `${i + 1}. ${b.name}: ${b.instruction || b.description || ''}`).join('\n')
    : 'Standard cinematic style with clear visuals';

  // Build episode context
  const episodeContext = episodeTopic
    ? `\n\n=== EPISODE TOPIC (MUST be the main subject) ===\nTitle: "${episodeTopic}"\nDescription: ${episodeDesc || 'N/A'}\n\nIMPORTANT: The video MUST be about "${episodeTopic}". Adapt the scene to focus on this topic.`
    : '';

  // Build character context
  const characterContext = characters && characters.length > 0
    ? `\n\n=== CHARACTERS ===\n${characters.map(c => `- ${c.name}: ${c.visualDescription || c.description || 'N/A'}`).join('\n')}`
    : '';

  console.log(`ðŸ”§ expandScenesWithTopic: Starting expansion of ${rawScenes.length} scenes`);
  console.log(`   Topic: "${episodeTopic || 'No Episode'}"`);
  console.log(`   Expander Blocks: ${expanderBlocks?.length || 0}`);

  // Per-Scene Loop (NOT bulk generation)
  for (let i = 0; i < rawScenes.length; i++) {
    const scene = rawScenes[i];
    const scenePrompt = scene.visualPrompt || scene.rawPrompt || scene.blockTitle || `Scene ${i + 1}`;
    const sceneInstruction = scene.sceneInstruction || '';

    // Build scene instruction context if available
    const sceneInstructionContext = sceneInstruction
      ? `\n\n=== SCENE INSTRUCTION (IMPORTANT - Follow this direction) ===\n${sceneInstruction}`
      : '';

    const systemPrompt = `You are a Premium Prompt Expander for AI video generation (Google Flow / Veo).

=== EXPANDER RULES ===
${blockInstructions}
${episodeContext}
${characterContext}
${sceneInstructionContext}

=== MODE CONTEXT ===
Category: ${modeCategory || 'Cinematic'}
System Instruction: ${systemInstruction || 'Create immersive video content'}

=== OUTPUT REQUIREMENTS ===
1. Write a DETAILED ${sceneDuration}-second video scene prompt in English (150-300 words)
2. Include: character appearances (if any), lighting, camera angles, ambient sounds, emotions
3. Be cinematic and immersive
4. The scene MUST be about "${episodeTopic || 'the main topic'}"
${sceneInstruction ? '5. FOLLOW the Scene Instruction above as the primary direction for this scene' : ''}
6. Output ONLY the expanded prompt, no explanations or markdown`;

    try {
      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Scene ${i + 1} of ${rawScenes.length}: ${scenePrompt}${sceneInstruction ? `\n\nScene Direction: ${sceneInstruction}` : ''}` }
        ],
        temperature: 0.7,
        max_tokens: 800
      });

      const expanded = response.choices[0]?.message?.content?.trim() || scenePrompt;

      expandedPrompts.push({
        sceneNumber: i + 1,
        englishPrompt: expanded,
        originalPrompt: scenePrompt,
        audioDescription: scene.audioAmbience || scene.audioInstruction || 'Ambient sounds',
        cameraAngle: scene.cameraAngle || 'wide',
        blockTitle: scene.blockTitle || `Scene ${i + 1}`
      });

      console.log(`   âœ… Scene ${i + 1}/${rawScenes.length} expanded (${expanded.length} chars)`);
    } catch (err) {
      console.error(`   âŒ Scene ${i + 1} expansion failed:`, err.message);
      // Fallback to original prompt
      expandedPrompts.push({
        sceneNumber: i + 1,
        englishPrompt: scenePrompt,
        originalPrompt: scenePrompt,
        audioDescription: scene.audioAmbience || 'Ambient sounds',
        cameraAngle: scene.cameraAngle || 'wide',
        blockTitle: scene.blockTitle || `Scene ${i + 1}`
      });
    }
  }

  console.log(`ðŸ expandScenesWithTopic: Completed ${expandedPrompts.length} scenes`);
  return expandedPrompts;
}

// ============================================
// SHARED HELPER: Generate Titles and Tags for all platforms
// ============================================
async function generateTitlesAndTags(params) {
  const {
    episodeTopic,
    episodeDesc,
    modeCategory,
    expandedPrompts
  } = params;

  const openai = getOpenAI();

  const prompt = `You are a social media expert. Generate engaging titles and tags for a video.

=== VIDEO TOPIC ===
Title: "${episodeTopic}"
Description: ${episodeDesc || 'N/A'}
Category: ${modeCategory || 'Entertainment'}
Number of Scenes: ${expandedPrompts?.length || 0}

=== OUTPUT FORMAT (JSON) ===
{
  "titles": {
    "tiktok": "Catchy TikTok title in Thai (max 100 chars)",
    "facebook": "Engaging Facebook title in Thai (max 150 chars)",
    "instagram": "Instagram caption in Thai (max 100 chars)",
    "youtube": "SEO-friendly YouTube title in Thai (max 100 chars)"
  },
  "tags": {
    "tiktok": ["5 relevant trending tags WITHOUT # symbol"],
    "facebook": ["3 engaging tags"],
    "instagram": ["30 relevant hashtags for maximum reach WITHOUT # symbol"],
    "youtube": ["10 SEO optimized tags"]
  }
}

IMPORTANT:
- ALL titles MUST be in Thai
- ALL tags must be relevant to "${episodeTopic}"
- Tags must NOT include the # symbol
- Output valid JSON only, no markdown`;

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: 'You are a social media expert. Output valid JSON only.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0.7,
      max_tokens: 1500
    });

    let content = response.choices[0].message.content.trim();
    content = content.replace(/```json/g, '').replace(/```/g, '').trim();

    return JSON.parse(content);
  } catch (err) {
    console.error('generateTitlesAndTags error:', err.message);
    // Fallback
    return {
      titles: {
        tiktok: episodeTopic || 'Video',
        facebook: episodeTopic || 'Video',
        instagram: episodeTopic || 'Video',
        youtube: episodeTopic || 'Video'
      },
      tags: {
        tiktok: ['video', 'viral', 'fyp', 'trending', 'content'],
        facebook: ['video', 'content', 'watch'],
        instagram: Array(30).fill('content'),
        youtube: Array(10).fill('video')
      }
    };
  }
}

// ============================================
// SHARED HELPER: Extract raw scenes from Mode data
// ============================================
function extractRawScenesFromMode(modeData) {
  const rawScenes = [];
  const characters = modeData.characters || [];
  const locations = modeData.locations || [];

  (modeData.blocks || []).forEach((block, blockIndex) => {
    // If block has evolution steps, extract each step as a scene
    if (block.evolution && block.evolution.length > 0) {
      block.evolution.forEach((step, stepIndex) => {
        const dialogues = (step.dialogues || []).map(d => {
          const char = characters.find(c => c.id === d.characterId);
          return {
            character: char?.name || 'Unknown',
            text: d.text || ''
          };
        });

        const location = locations.find(l => l.id === step.locationId);

        rawScenes.push({
          sceneNumber: rawScenes.length + 1,
          blockTitle: block.title || `Scene ${blockIndex + 1}`,
          visualPrompt: step.rawPrompt || block.title || '',
          rawPrompt: step.rawPrompt || '',
          sceneInstruction: step.sceneInstruction || '',
          audioAmbience: step.audioInstruction || '',
          audioInstruction: step.audioInstruction || '',
          cameraAngle: step.cameraAngle || 'wide',
          timeOfDay: step.timeOfDay || 'day',
          locationName: location?.name || '',
          dialogues: dialogues
        });
      });
    } else {
      // Block without evolution - use block title as scene
      rawScenes.push({
        sceneNumber: rawScenes.length + 1,
        blockTitle: block.title || `Scene ${blockIndex + 1}`,
        visualPrompt: block.title || '',
        rawPrompt: '',
        audioAmbience: '',
        cameraAngle: 'wide',
        timeOfDay: 'day',
        dialogues: []
      });
    }
  });

  return rawScenes;
}

// ============================================
// SHARED HELPER: Get Next Episode from Queue
// Supports: sequential (order asc) or random selection
// ============================================
async function getNextEpisode(projectRef, selectionMode = 'sequential') {
  const episodesRef = projectRef.collection('episodes');
  
  // Query only pending episodes
  let query = episodesRef.where('status', '==', 'pending');

  if (selectionMode === 'random') {
    // Random: fetch all pending then pick one randomly
    const snapshot = await query.get();
    if (snapshot.empty) return null;

    const randomIndex = Math.floor(Math.random() * snapshot.size);
    const doc = snapshot.docs[randomIndex];
    return { id: doc.id, ref: doc.ref, ...doc.data() };
  } else {
    // Sequential: order by 'order' field ascending, get first
    query = query.orderBy('order', 'asc').limit(1);
    const snapshot = await query.get();
    if (snapshot.empty) return null;

    const doc = snapshot.docs[0];
    return { id: doc.id, ref: doc.ref, ...doc.data() };
  }
}

// ============================================
// SHARED HELPER: Get Remaining Episode Count
// ============================================
async function getRemainingEpisodeCount(projectRef) {
  const snapshot = await projectRef.collection('episodes')
    .where('status', '==', 'pending')
    .get();
  return snapshot.size;
}

exports.consultantChat = functions.https.onCall(async (data, context) => {
  try {
    const openai = getOpenAI();
    const { message, history, currentModeData, aiMode = 'architect' } = data;

    // System prompt for Architect Mode (à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¹€à¸£à¸·à¹ˆà¸­à¸‡)
    const architectSystemPrompt = `You are "AI Mode Architect" - à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸­à¸­à¸à¹à¸šà¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Mode ðŸŽ¬

[ðŸŽ¯ CORE MISSION]
à¸Šà¹ˆà¸§à¸¢ User à¸­à¸­à¸à¹à¸šà¸š "à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸‰à¸²à¸" à¸ªà¸³à¸«à¸£à¸±à¸šà¸§à¸´à¸”à¸µà¹‚à¸­
- Mode = Template à¸—à¸µà¹ˆà¸¡à¸µà¸Šà¸·à¹ˆà¸­à¸‰à¸²à¸à¸«à¸¥à¸²à¸¢à¹† à¸‰à¸²à¸
- Expander à¸ˆà¸°à¸‚à¸¢à¸²à¸¢ Prompt à¹ƒà¸«à¹‰à¸ à¸²à¸¢à¸«à¸¥à¸±à¸‡ (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™ Prompt à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”)
- à¹ƒà¸Šà¹‰ [TOPIC] à¹€à¸›à¹‡à¸™ Placeholder à¸ªà¸³à¸«à¸£à¸±à¸šà¸«à¸±à¸§à¸‚à¹‰à¸­à¸ˆà¸²à¸ Content Queue

[ðŸ“‹ RESPONSE FORMAT - JSON à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™]
{
  "reply": "à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸•à¸­à¸šà¸à¸¥à¸±à¸š",
  "options": ["à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸1", "à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸2"] à¸«à¸£à¸·à¸­ null,
  "suggestedFix": null à¸«à¸£à¸·à¸­ { Mode Object },
  "inputFields": null
}

[ðŸ’¬ CONVERSATION FLOW]
à¸•à¹‰à¸­à¸‡à¸„à¸¸à¸¢à¸à¸±à¸š User à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸£à¸šà¸à¹ˆà¸­à¸™à¸ªà¸£à¹‰à¸²à¸‡ Mode:

1. **à¸–à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸§à¸´à¸”à¸µà¹‚à¸­** (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸£à¸¹à¹‰)
   - à¸ªà¸²à¸£à¸„à¸”à¸µ / à¹€à¸¥à¹ˆà¸²à¹€à¸£à¸·à¹ˆà¸­à¸‡ / à¸ªà¸­à¸™ / à¸šà¸±à¸™à¹€à¸—à¸´à¸‡?
   - à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ options: ["ðŸ“š à¸ªà¸²à¸£à¸„à¸”à¸µ", "ðŸŽ­ à¹€à¸¥à¹ˆà¸²à¹€à¸£à¸·à¹ˆà¸­à¸‡", "ðŸ“– à¸ªà¸­à¸™à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰", "ðŸŽ¬ à¸šà¸±à¸™à¹€à¸—à¸´à¸‡"]

2. **à¸–à¸²à¸¡à¸ˆà¸³à¸™à¸§à¸™à¸‰à¸²à¸à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£** (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸£à¸¹à¹‰)
   - à¹ƒà¸«à¹‰ User à¸žà¸´à¸¡à¸žà¹Œà¸ˆà¸³à¸™à¸§à¸™à¹€à¸­à¸‡ (à¹„à¸¡à¹ˆà¸ˆà¸³à¸à¸±à¸”, à¹à¸™à¸°à¸™à¸³ 3-10 à¸‰à¸²à¸)
   - à¸–à¸²à¸¡à¸§à¹ˆà¸² "à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸µà¹ˆà¸‰à¸²à¸à¸„à¸£à¸±à¸š? (à¹à¸™à¸°à¸™à¸³ 3-10 à¸‰à¸²à¸ à¹à¸•à¹ˆà¹ƒà¸ªà¹ˆà¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸™à¸µà¹‰à¹„à¸”à¹‰)"

3. **à¸–à¸²à¸¡à¹‚à¸—à¸™à¸«à¸£à¸·à¸­à¸šà¸£à¸£à¸¢à¸²à¸à¸²à¸¨** (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸£à¸¹à¹‰)
   - à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ options: ["ðŸ”¥ à¸”à¸£à¸²à¸¡à¹ˆà¸²", "ðŸ˜Š à¸ªà¸™à¸¸à¸à¸ªà¸™à¸²à¸™", "ðŸ˜¢ à¸‹à¸¶à¹‰à¸‡", "ðŸ˜± à¸£à¸°à¸—à¸¶à¸"]

4. **à¸–à¸²à¸¡ System Instruction (The Brain)** (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸£à¸¹à¹‰)
   - à¸–à¸²à¸¡à¸§à¹ˆà¸² "à¸­à¸¢à¸²à¸à¹ƒà¸«à¹‰ AI à¸¡à¸µà¸šà¸—à¸šà¸²à¸—à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£à¸„à¸£à¸±à¸š? à¹€à¸Šà¹ˆà¸™ 'à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸à¸³à¸à¸±à¸šà¸«à¸™à¸±à¸‡à¸—à¸µà¹ˆà¹€à¸™à¹‰à¸™à¸”à¸£à¸²à¸¡à¹ˆà¸²'"
   - à¸«à¸£à¸·à¸­à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸§à¸´à¸”à¸µà¹‚à¸­

5. **à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸”à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸£à¸š â†’ à¹€à¸ªà¸™à¸­à¸ªà¸£à¹‰à¸²à¸‡ Mode**
   - à¸ªà¸£à¸¸à¸›à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸ˆà¸°à¸ªà¸£à¹‰à¸²à¸‡
   - à¹ƒà¸«à¹‰ options: ["âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸¥à¸¢!", "ðŸ”„ à¸›à¸£à¸±à¸šà¹à¸à¹‰à¸à¹ˆà¸­à¸™"]

[ðŸŽ¬ WHEN USER CONFIRMS OR CLICKS "à¸ªà¸£à¹‰à¸²à¸‡ Mode"]
à¸£à¸°à¸šà¸šà¸ˆà¸°à¸ªà¹ˆà¸‡ message à¸žà¸´à¹€à¸¨à¸©: "[[GENERATE_MODE]]" à¸«à¸£à¸·à¸­ User à¸šà¸­à¸ "à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸¥à¸¢"

à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸”à¹‰à¸£à¸±à¸š â†’ à¸ªà¸£à¹‰à¸²à¸‡ Mode à¸—à¸±à¸™à¸—à¸µ:

[ðŸ“ MODE STRUCTURE - à¹ƒà¸«à¸¡à¹ˆ! (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µ rawPrompt)]
{
  "name": "à¸Šà¸·à¹ˆà¸­ Mode",
  "description": "à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¸ªà¸±à¹‰à¸™à¹†",
  "category": "cinematic",
  "systemInstruction": "à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¸šà¸—à¸šà¸²à¸—à¸‚à¸­à¸‡ AI à¸ªà¸³à¸«à¸£à¸±à¸š Mode à¸™à¸µà¹‰ à¹€à¸Šà¹ˆà¸™ 'à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸à¸³à¸à¸±à¸šà¸«à¸™à¸±à¸‡à¸—à¸µà¹ˆà¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¸”à¹‰à¸²à¸™à¸”à¸£à¸²à¸¡à¹ˆà¸²...'",
  "blocks": [
    {
      "id": 1,
      "title": "[TOPIC] - à¸‰à¸²à¸ 1: à¹€à¸›à¸´à¸”à¹€à¸£à¸·à¹ˆà¸­à¸‡",
      "sequencePercentage": 20,
      "evolution": [{ "id": 101, "stepPercentage": 100 }]
    },
    {
      "id": 2,
      "title": "[TOPIC] - à¸‰à¸²à¸ 2: à¹à¸™à¸°à¸™à¸³à¸›à¸±à¸à¸«à¸²",
      "sequencePercentage": 25,
      "evolution": [{ "id": 102, "stepPercentage": 100 }]
    },
    ...
  ]
}

[ðŸŽ­ SCENE TITLE EXAMPLES]
à¹ƒà¸Šà¹‰ [TOPIC] + à¸Šà¸·à¹ˆà¸­à¸‰à¸²à¸à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢:
- "[TOPIC] - à¹€à¸›à¸´à¸”à¹€à¸£à¸·à¹ˆà¸­à¸‡: à¸žà¸šà¸à¸±à¸šà¸•à¸±à¸§à¸¥à¸°à¸„à¸£à¸«à¸¥à¸±à¸"
- "[TOPIC] - à¸›à¸±à¸à¸«à¸²: à¹€à¸œà¸Šà¸´à¸à¸­à¸¸à¸›à¸ªà¸£à¸£à¸„"
- "[TOPIC] - à¸ˆà¸¸à¸”à¸žà¸¥à¸´à¸: à¸„à¹‰à¸™à¸žà¸šà¸„à¸§à¸²à¸¡à¸ˆà¸£à¸´à¸‡"
- "[TOPIC] - à¹„à¸„à¸¥à¹à¸¡à¸à¸‹à¹Œ: à¸à¸²à¸£à¹€à¸œà¸Šà¸´à¸à¸«à¸™à¹‰à¸²à¸„à¸£à¸±à¹‰à¸‡à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢"
- "[TOPIC] - à¸šà¸—à¸ªà¸£à¸¸à¸›: à¸ˆà¸šà¹€à¸£à¸·à¹ˆà¸­à¸‡"

[ðŸŽ­ STORY STRUCTURE GUIDE]
- Act 1 (15-20%): Hook - à¸”à¸¶à¸‡à¸”à¸¹à¸”à¸„à¸™à¸”à¸¹
- Act 2 (25-30%): Setup - à¹à¸™à¸°à¸™à¸³à¸›à¸±à¸à¸«à¸²
- Act 3 (35-40%): Rising Action - à¹€à¸‚à¹‰à¸¡à¸‚à¹‰à¸™à¸‚à¸¶à¹‰à¸™
- Act 4 (15-20%): Climax - à¸ˆà¸¸à¸”à¸žà¸µà¸„

[âš¡ IMPORTANT]
- à¸•à¸­à¸šà¸à¸¥à¸±à¸šà¹€à¸ªà¸¡à¸­ à¸«à¹‰à¸²à¸¡à¹€à¸‡à¸µà¸¢à¸š
- à¸–à¸²à¸¡à¸—à¸µà¸¥à¸°à¸„à¸³à¸–à¸²à¸¡ à¹„à¸¡à¹ˆà¸–à¸²à¸¡à¸«à¸¥à¸²à¸¢à¸­à¸¢à¹ˆà¸²à¸‡à¸žà¸£à¹‰à¸­à¸¡à¸à¸±à¸™
- à¹ƒà¸Šà¹‰ options à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰ User à¹€à¸¥à¸·à¸­à¸à¸‡à¹ˆà¸²à¸¢
- à¸ªà¸£à¹‰à¸²à¸‡ Mode à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸”à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸£à¸š + User à¸¢à¸·à¸™à¸¢à¸±à¸™`;

    // System prompt for Instruction Mode (à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸)
    const instructionSystemPrompt = `You are "AI Scene Writer" - à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¹€à¸‚à¸µà¸¢à¸™à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸ ðŸŽ¬

[ðŸŽ¯ CORE MISSION]
à¸Šà¹ˆà¸§à¸¢ User à¹€à¸‚à¸µà¸¢à¸™ "à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸ (Scene Instruction)" à¸ªà¸³à¸«à¸£à¸±à¸šà¸‰à¸²à¸à¹ƒà¸™ Mode
- à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸ = à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸µà¹ˆà¸¢à¸·à¸”à¸«à¸¢à¸¸à¹ˆà¸™ à¸šà¸­à¸à¸§à¹ˆà¸²à¸‰à¸²à¸à¸™à¸µà¹‰à¸„à¸§à¸£à¸¡à¸µà¸­à¸°à¹„à¸£
- à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸ [TOPIC] à¸•à¸£à¸‡à¹† à¹€à¸žà¸£à¸²à¸° Episode à¸ˆà¸°à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸›à¹€à¸£à¸·à¹ˆà¸­à¸¢à¹†
- à¹€à¸‚à¸µà¸¢à¸™à¹€à¸›à¹‡à¸™à¹à¸™à¸§à¸—à¸²à¸‡à¸—à¸µà¹ˆ AI Expander à¸ˆà¸°à¸™à¸³à¹„à¸›à¹ƒà¸Šà¹‰à¸‚à¸¢à¸²à¸¢à¸„à¸§à¸²à¸¡

[ðŸ“‹ RESPONSE FORMAT - JSON à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™]
{
  "reply": "à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸•à¸­à¸šà¸à¸¥à¸±à¸š",
  "options": ["à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸1", "à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸2"] à¸«à¸£à¸·à¸­ null,
  "sceneInstructions": [
    { "blockIndex": 0, "instruction": "à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸ 1" },
    { "blockIndex": 1, "instruction": "à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸ 2" }
  ] à¸«à¸£à¸·à¸­ null
}

[ðŸ’¬ CONVERSATION FLOW]
1. **à¸–à¸²à¸¡à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸‰à¸²à¸à¹„à¸«à¸™**
   - à¸”à¸¹ blocks à¹ƒà¸™ currentModeData à¹à¸¥à¹‰à¸§à¹à¸ªà¸”à¸‡à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸‰à¸²à¸
   - à¹ƒà¸«à¹‰ options à¸£à¸§à¸¡à¸–à¸¶à¸‡ "ðŸŽ¬ à¸—à¸¸à¸à¸‰à¸²à¸" à¹€à¸žà¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§
   - à¹ƒà¸«à¹‰ options à¹à¸•à¹ˆà¸¥à¸°à¸‰à¸²à¸à¸”à¹‰à¸§à¸¢

2. **à¹€à¸¡à¸·à¹ˆà¸­ User à¹€à¸¥à¸·à¸­à¸ "à¸—à¸¸à¸à¸‰à¸²à¸" à¸«à¸£à¸·à¸­à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸¸à¸à¸‰à¸²à¸**
   - à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ block à¸—à¸±à¸™à¸—à¸µ
   - Return sceneInstructions array à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸„à¸£à¸šà¸—à¸¸à¸à¸‰à¸²à¸

3. **à¹€à¸¡à¸·à¹ˆà¸­ User à¹€à¸¥à¸·à¸­à¸à¸‰à¸²à¸à¹€à¸”à¸µà¸¢à¸§**
   - à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸‰à¸²à¸à¸™à¸±à¹‰à¸™
   - Return sceneInstructions array à¸—à¸µà¹ˆà¸¡à¸µ 1 item

[ðŸ“ SCENE INSTRUCTION EXAMPLES]
à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸à¸—à¸µà¹ˆà¸”à¸µà¸„à¸§à¸£:
- **à¸¢à¸·à¸”à¸«à¸¢à¸¸à¹ˆà¸™**: à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸ topic à¸•à¸²à¸¢à¸•à¸±à¸§ à¹ƒà¸Šà¹‰à¸„à¸³à¸§à¹ˆà¸² "à¸«à¸±à¸§à¸‚à¹‰à¸­à¸«à¸¥à¸±à¸" à¸«à¸£à¸·à¸­ "à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸—à¸µà¹ˆà¸à¸³à¸¥à¸±à¸‡à¹€à¸¥à¹ˆà¸²"
- **à¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡**: à¸šà¸­à¸à¸§à¹ˆà¸²à¸‰à¸²à¸à¸„à¸§à¸£à¸¡à¸µà¸­à¸°à¹„à¸£ (à¹€à¸›à¸´à¸”à¸‰à¸²à¸à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£, à¸ˆà¸šà¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£)
- **à¸¡à¸µà¸­à¸²à¸£à¸¡à¸“à¹Œ**: à¸à¸³à¸«à¸™à¸”à¹‚à¸—à¸™à¸‚à¸­à¸‡à¸‰à¸²à¸

à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‰à¸²à¸:
- à¸‰à¸²à¸à¹€à¸›à¸´à¸”à¹€à¸£à¸·à¹ˆà¸­à¸‡: "à¹€à¸›à¸´à¸”à¸‰à¸²à¸à¸”à¹‰à¸§à¸¢ wide shot à¹à¸™à¸°à¸™à¸³à¸ªà¸–à¸²à¸™à¸—à¸µà¹ˆà¸«à¸¥à¸±à¸ à¸šà¸£à¸£à¸¢à¸²à¸à¸²à¸¨à¸ªà¸‡à¸š à¸„à¹ˆà¸­à¸¢à¹† zoom à¹€à¸‚à¹‰à¸²à¸«à¸²à¸•à¸±à¸§à¸¥à¸°à¸„à¸£à¸«à¸¥à¸±à¸ à¹à¸ªà¸”à¸‡à¸„à¸§à¸²à¸¡à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹‚à¸¢à¸‡à¸à¸±à¸šà¸«à¸±à¸§à¸‚à¹‰à¸­à¸—à¸µà¹ˆà¸à¸³à¸¥à¸±à¸‡à¹€à¸¥à¹ˆà¸²"
- à¸‰à¸²à¸à¹à¸™à¸°à¸™à¸³à¸›à¸±à¸à¸«à¸²: "à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸šà¸£à¸£à¸¢à¸²à¸à¸²à¸¨à¹€à¸›à¹‡à¸™à¸„à¸§à¸²à¸¡à¸•à¸¶à¸‡à¹€à¸„à¸£à¸µà¸¢à¸” à¹à¸™à¸°à¸™à¸³à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¸«à¸±à¸§à¸‚à¹‰à¸­ à¸•à¸±à¸§à¸¥à¸°à¸„à¸£à¹à¸ªà¸”à¸‡à¸„à¸§à¸²à¸¡à¸à¸±à¸‡à¸§à¸¥"
- à¸‰à¸²à¸à¸ªà¸³à¸£à¸§à¸ˆ: "à¸•à¸±à¸§à¸¥à¸°à¸„à¸£à¸ªà¸³à¸£à¸§à¸ˆà¸«à¸£à¸·à¸­à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸«à¸±à¸§à¸‚à¹‰à¸­ à¹ƒà¸Šà¹‰à¸à¸²à¸£à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸à¸¥à¹‰à¸­à¸‡à¸«à¸¥à¸²à¸à¸«à¸¥à¸²à¸¢ à¹à¸ªà¸”à¸‡à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸—à¸µà¹ˆà¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆ"
- à¸‰à¸²à¸à¸„à¹‰à¸™à¸žà¸š: "à¸ˆà¸¸à¸”à¸žà¸µà¸„à¸‚à¸­à¸‡à¹€à¸£à¸·à¹ˆà¸­à¸‡ à¸•à¸±à¸§à¸¥à¸°à¸„à¸£à¸„à¹‰à¸™à¸žà¸šà¸ªà¸´à¹ˆà¸‡à¸ªà¸³à¸„à¸±à¸ à¹ƒà¸Šà¹‰ dramatic lighting à¹à¸¥à¸° close-up"
- à¸‰à¸²à¸à¸šà¸—à¸ªà¸£à¸¸à¸›: "à¸ªà¸£à¸¸à¸›à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸£à¸²à¸§ à¹à¸ªà¸”à¸‡ resolution à¸šà¸£à¸£à¸¢à¸²à¸à¸²à¸¨à¸œà¹ˆà¸­à¸™à¸„à¸¥à¸²à¸¢ à¸›à¸´à¸”à¸—à¹‰à¸²à¸¢à¸”à¹‰à¸§à¸¢ message à¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™"

[âš¡ IMPORTANT]
- à¸­à¹ˆà¸²à¸™ currentModeData.blocks à¹€à¸žà¸·à¹ˆà¸­à¸”à¸¹à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸‰à¸²à¸à¸—à¸µà¹ˆà¸¡à¸µ
- à¹€à¸¡à¸·à¹ˆà¸­ User à¸šà¸­à¸ "à¸—à¸¸à¸à¸‰à¸²à¸" à¹ƒà¸«à¹‰à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸„à¸£à¸šà¸—à¸¸à¸ block à¸—à¸±à¸™à¸—à¸µ
- à¸•à¸­à¸šà¸à¸¥à¸±à¸šà¹€à¸ªà¸¡à¸­ à¸«à¹‰à¸²à¸¡à¹€à¸‡à¸µà¸¢à¸š
- sceneInstructions à¸•à¹‰à¸­à¸‡à¸¡à¸µ blockIndex à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸š index à¸‚à¸­à¸‡ blocks array`;

    // Select system prompt based on aiMode
    const systemPrompt = aiMode === 'instruction' ? instructionSystemPrompt : architectSystemPrompt;

    const fullHistory = [
      { role: 'system', content: systemPrompt },
      ...history,
      {
        role: 'user',
        content: `Current Mode Data: ${JSON.stringify(currentModeData)} \n\nUser Request: ${message}`
      }
    ];

    // Add explicit JSON instruction to satisfy OpenAI API requirement
    const messagesWithJsonHint = [
      ...fullHistory,
      { role: 'system', content: 'IMPORTANT: Always respond with valid JSON format only. No other text.' }
    ];

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: messagesWithJsonHint,
      temperature: 0.3,
      response_format: { type: "json_object" }
    });

    return JSON.parse(completion.choices[0].message.content);

  } catch (error) {
    console.error('Error in consultantChat:', error);
    throw new functions.https.HttpsError('internal', error.message);
  }
});

// --- 4. Generate User Key (For Extension Access) ---
// ADMIN EMAIL - can be moved to Firestore config later
const ADMIN_EMAILS = ['fxfarm.dashboard@gmail.com'];

exports.generateUserKey = functions.https.onCall(async (data, context) => {
  // Require authentication
  if (!context.auth) {
    throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
  }

  const userId = context.auth.uid;
  const userEmail = context.auth.token.email || '';

  try {
    const db = admin.firestore();

    // Check if user is admin
    const isAdmin = ADMIN_EMAILS.includes(userEmail.toLowerCase());

    // Generate unique key: base64(userId:isAdmin:timestamp:random)
    const timestamp = Date.now();
    const random = Math.random().toString(36).substring(2, 10);
    const adminFlag = isAdmin ? 'ADMIN' : 'USER';
    const rawKey = `${userId}:${adminFlag}:${timestamp}:${random}`;
    const encodedKey = Buffer.from(rawKey).toString('base64');

    // Store key in user document
    await db.collection('users').doc(userId).set({
      extensionKey: {
        keyHash: Buffer.from(encodedKey).toString('base64'),
        createdAt: admin.firestore.FieldValue.serverTimestamp(),
        isAdmin: isAdmin,
        active: true
      }
    }, { merge: true });

    console.log(`ðŸ”‘ User Key generated for ${userEmail} (Admin: ${isAdmin})`);

    return {
      success: true,
      key: encodedKey,
      isAdmin: isAdmin,
      message: isAdmin
        ? 'Admin Key generated! You have full access to recording features.'
        : 'User Key generated! You can monitor and execute scheduled jobs.'
    };

  } catch (error) {
    console.error('Error generating key:', error);
    throw new functions.https.HttpsError('internal', error.message);
  }
});

// --- 4.5 AI Prompt Compiler (Translate THâ†’EN + Compile Scenes) ---
exports.compilePrompts = functions
  .runWith({ secrets: ['OPENAI_API_KEY'], timeoutSeconds: 120 })
  .https.onCall(async (data, context) => {
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }

    const { modeData, variableValues } = data;

    if (!modeData || !modeData.blocks) {
      throw new functions.https.HttpsError('invalid-argument', 'Mode data with blocks is required');
    }

    try {
      const openai = getOpenAI();

      // 1. Build COMPLETE context from Mode
      const systemInstruction = modeData.systemInstruction || '';
      const category = modeData.category || 'Cinematic';
      const description = modeData.description || '';
      const characters = modeData.characters || [];
      const locations = modeData.locations || [];
      const storyOverview = modeData.storyOverview || {};

      // 2. Extract all scenes with COMPLETE data
      const rawScenes = [];
      (modeData.blocks || []).forEach((block, blockIndex) => {
        (block.evolution || []).forEach((step, stepIndex) => {
          // Get dialogues with character info
          const dialogues = (step.dialogues || []).map(d => {
            const char = characters.find(c => c.id === d.characterId);
            return {
              character: char?.name || 'Unknown',
              voiceStyle: char?.voiceStyle || 'neutral',
              visualDescription: char?.visualDescription || '',
              text: d.text || '',
              timing: d.timing || 'start'
            };
          });

          // Get location info
          const location = locations.find(l => l.id === step.locationId);

          rawScenes.push({
            sceneNumber: rawScenes.length + 1,
            blockTitle: block.title || `Scene ${blockIndex + 1}`,
            visualPrompt: step.rawPrompt || '',
            audioAmbience: step.audioInstruction || '',
            cameraAngle: step.cameraAngle || 'wide',
            locationName: location?.name || '',
            locationVisual: location?.visualDescription || '',
            timeOfDay: step.timeOfDay || 'day',
            bgmMood: step.bgmMood || 'epic',
            backgroundVoices: step.backgroundVoices || '',
            dialogues: dialogues
          });
        });
      });

      // 3. Build DETAILED prompt for AI
      const characterDescriptions = characters.map(c =>
        `- ${c.name} (${c.role || 'main'}): ${c.description || 'No role'}\n  Appearance: ${c.visualDescription || 'Not specified'}\n  Voice: ${c.voiceStyle || 'neutral'}`
      ).join('\n') || 'None';

      const locationDescriptions = locations.map(l =>
        `- ${l.name}: ${l.visualDescription || 'No description'}`
      ).join('\n') || 'None';

      const sceneDescriptions = rawScenes.map((s, i) => {
        let sceneText = `\nScene ${i + 1} (${s.blockTitle}):\n`;
        sceneText += `  Location: ${s.locationName || 'Not specified'} - ${s.locationVisual}\n`;
        sceneText += `  Time: ${s.timeOfDay}\n`;
        sceneText += `  Visual: ${s.visualPrompt}\n`;
        sceneText += `  Audio Ambience: ${s.audioAmbience}\n`;
        sceneText += `  BGM Mood: ${s.bgmMood}\n`;
        sceneText += `  Camera: ${s.cameraAngle}\n`;
        if (s.backgroundVoices) {
          sceneText += `  Background Voices: ${s.backgroundVoices}\n`;
        }
        if (s.dialogues.length > 0) {
          sceneText += `  Dialogues:\n`;
          s.dialogues.forEach(d => {
            sceneText += `    - ${d.character} (${d.timing}): "${d.text}"\n`;
          });
        }
        return sceneText;
      }).join('\n');

      const aiPrompt = `You are a professional cinematic video prompt engineer. Your task is to:
1. Read the following Thai video mode description COMPLETELY
2. Create cohesive, connected scenes that tell a COMPLETE story
3. Translate everything to English for AI video generation
4. Each scene is 8 seconds long - make prompts appropriate for this duration
5. Ensure VISUAL CONTINUITY - characters must look the same in every scene
6. Include character appearance details in EVERY scene prompt

=== STORY OVERVIEW ===
Synopsis: ${storyOverview.synopsis || 'Not provided'}
Theme: ${storyOverview.theme || 'Not provided'}
Tone: ${storyOverview.tone || 'epic'}
Target Duration: ${storyOverview.totalDuration || '3-5 min'}

=== MODE CONTEXT ===
Category: ${category}
Description: ${description}
System Instruction: ${systemInstruction}

=== CHARACTERS (IMPORTANT - Include appearance in every scene) ===
${characterDescriptions}

=== LOCATIONS ===
${locationDescriptions}

=== RAW SCENES (in Thai) ===
${sceneDescriptions}

=== OUTPUT FORMAT (JSON array) ===
[
  {
    "sceneNumber": 1,
    "englishPrompt": "DETAILED English prompt including character appearances, location details, lighting based on time of day, 8 seconds...",
    "audioDescription": "Sound effects, ambient sounds, and music mood in English...",
    "cameraMovement": "Specific camera angle and movement in English...",
    "dialogueScript": "Character dialogue in English with timing markers...",
    "backgroundVoices": "Background/ambient character voices if any..."
  }
]

=== CRITICAL RULES ===
- ALWAYS include character visual descriptions (clothing, appearance) in englishPrompt
- Match lighting to timeOfDay (dawn=golden, day=bright, sunset=warm orange, night=dark blue)
- Keep BGM mood consistent with bgmMood field
- Make scenes flow naturally - this is a cohesive story
- Each prompt must be self-contained with all visual details for AI video generation
- Translate Thai to natural, cinematic English`;

      // 4. Call OpenAI
      const completion = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: 'You are a video prompt engineer. Output valid JSON only.' },
          { role: 'user', content: aiPrompt }
        ],
        temperature: 0.7,
        max_tokens: 4000
      });

      const responseText = completion.choices[0]?.message?.content || '[]';

      // 5. Parse JSON response
      let compiledScenes;
      try {
        // Extract JSON from response (handle markdown code blocks)
        const jsonMatch = responseText.match(/\[[\s\S]*\]/);
        compiledScenes = jsonMatch ? JSON.parse(jsonMatch[0]) : [];
      } catch (parseErr) {
        console.error('Failed to parse AI response:', parseErr);
        compiledScenes = rawScenes.map((s, i) => ({
          sceneNumber: i + 1,
          englishPrompt: s.visualPrompt,
          audioDescription: s.audioAmbience,
          cameraMovement: s.cameraAngle,
          dialogueScript: s.dialogues.map(d => `${d.character}: ${d.text}`).join('; ')
        }));
      }

      console.log(`âœ… Compiled ${compiledScenes.length} scenes`);

      return {
        success: true,
        compiledScenes: compiledScenes,
        rawSceneCount: rawScenes.length
      };

    } catch (error) {
      console.error('Prompt compilation error:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// --- 5. Central Scheduler (The Station Master) ---
exports.scheduleJobs = functions.pubsub.schedule('every 1 minutes')
  .timeZone('UTC') // Run in UTC to handle all offsets manually
  // Force Deploy Change: v3.1 (Debug)
  .onRun(async (context) => {
    const db = admin.firestore();
    const now = new Date();
    console.log(`ðŸš‚ SUPER-SCHEDULER v3.0 START: ${now.toISOString()}`);

    try {
      // 1. Get ALL Running Projects
      // NOTE: This Collection Group query requires a Composite Index on 'projects' -> 'status'.
      const runningProjectsSnap = await db.collectionGroup('projects')
        .where('status', '==', 'running')
        .get();

      if (runningProjectsSnap.empty) {
        console.log('ðŸ’¤ No running projects found (empty snapshot). Scheduler sleeping.');
        return;
      }

      console.log(`Found ${runningProjectsSnap.size} running projects.`);

      // 2. Group Projects by User (Optimization to fetch User Profile once)
      const projectsByUser = {};
      runningProjectsSnap.docs.forEach(doc => {
        const p = doc.data();
        const userId = doc.ref.parent.parent.id;
        if (!projectsByUser[userId]) projectsByUser[userId] = [];
        projectsByUser[userId].push({ id: doc.id, ref: doc.ref, data: p });
      });

      // 3. Process each User
      for (const userId of Object.keys(projectsByUser)) {
        try {
          // A. Fetch User Timezone
          const userDoc = await db.collection('users').doc(userId).get();
          const userTz = (userDoc.exists && userDoc.data().timezone) ? userDoc.data().timezone : 'Asia/Bangkok';

          // B. Calculate User's Local Time (Robust Method using Intl.DateTimeFormat)
          const formatter = new Intl.DateTimeFormat('en-US', {
            timeZone: userTz,
            year: 'numeric',
            month: 'numeric',
            day: 'numeric',
            hour: 'numeric',
            minute: 'numeric',
            second: 'numeric',
            hour12: false,
            weekday: 'short'
          });

          const parts = formatter.formatToParts(now);
          const getPart = (type) => parts.find(p => p.type === type).value;

          const currentHour = getPart('hour').padStart(2, '0').replace('24', '00'); // Safety for 24-hour glitches
          const currentMinute = getPart('minute').padStart(2, '0');
          const currentTimeStr = `${currentHour}:${currentMinute}`;

          // Weekday comes from formatter as 'Sun', 'Mon' etc. - We need lowercase 'sun', 'mon'
          const currentDay = getPart('weekday').toLowerCase();

          // Double check if '24' issue pushed day forward incorrectly? 
          // Actually Intl.DateTimeFormat handles day rollover correctly, so the 'weekday' part should be correct for the user's localized time.

          if (!currentDay) {
            console.error(`âŒ Error calculating day for User ${userId}. TZ: ${userTz}, RawParts: ${JSON.stringify(parts)}`);
            continue;
          }

          console.log(`ðŸ‘¤ User: ${userId} | TZ: ${userTz} | Local: ${currentDay.toUpperCase()} ${currentTimeStr}`);

          // C. Check Projects for this User
          // Helper to normalize time string for comparison (e.g. 09:05 -> 09:05, 9:5 -> 09:05)
          const normalizeTime = (t) => {
            if (!t) return "";
            const parts = String(t).trim().split(':');
            if (parts.length !== 2) return String(t).trim();
            return `${String(parts[0]).padStart(2, '0')}:${String(parts[1]).padStart(2, '0')}`;
          };

          for (const project of projectsByUser[userId]) {
            // Check Slots (Only for current day)
            // Firestore query inside loop is okay if scale is low, but better to structure slots differently later or read all slots.
            // For now, let's query slots for the current day.
            const slotsRef = project.ref.collection('slots').where('day', '==', currentDay);
            const slotsSnap = await slotsRef.get();

            if (slotsSnap.empty) {
              // console.log(`   [${project.data.name}] No slots found for ${currentDay}`);
              continue;
            }

            console.log(`   ðŸ“‚ [${project.data.name}] found ${slotsSnap.size} slots for ${currentDay}. Checking matches...`);

            for (const slotDoc of slotsSnap.docs) {
              const slot = slotDoc.data();
              const slotStartNormalized = normalizeTime(slot.start);

              // --- DEBUG: LOG EVERYTHING ---
              console.log(`      ðŸ” Checking Slot: '${slot.start}' | Normalized: '${slotStartNormalized}' | Current: '${currentTimeStr}'`);

              // EXACT MATCH CHECK (Normalized)
              if (slotStartNormalized === currentTimeStr) {
                console.log(`      âœ… MATCH FOUND! Project: ${project.data.name} @ ${slot.start}`);

                // D. IDEMPOTENCY & JOB CREATION
                const jobId = `job_${project.id}_${currentDay}_${slotStartNormalized.replace(':', '')}_${new Date().toISOString().split('T')[0]}`;
                const jobRef = db.collection('agent_jobs').doc(jobId);
                const jobExists = await jobRef.get();

                if (!jobExists.exists) {
                  // Extract scene data from Mode (prefer compiledScenes if available)
                  const variableValues = project.data.variableValues || {};
                  let prompts = []; // Final prompts to use (English)
                  let scenes = []; // Complete scene objects
                  let modeMetadata = {};
                  let episodeData = null; // Episode from Content Queue

                  // === CONTENT QUEUE INTEGRATION using SHARED HELPER ===
                  // Get episode selection mode from project settings (default: sequential)
                  const episodeSelectionMode = project.data.episodeSelection || 'sequential';
                  console.log(`      ðŸŽ¯ Episode selection mode: ${episodeSelectionMode}`);

                  // Use SHARED getNextEpisode helper
                  const episodeResult = await getNextEpisode(project.ref, episodeSelectionMode);

                  if (episodeResult) {
                    episodeData = episodeResult;
                    console.log(`      ðŸ“º Episode from Queue: "${episodeData.title}" (mode: ${episodeSelectionMode})`);

                    // Mark episode as processing
                    await episodeResult.ref.update({
                      status: 'processing',
                      processingStartedAt: admin.firestore.FieldValue.serverTimestamp()
                    });
                  } else {
                    console.log(`      âš ï¸ No pending episodes in queue, using Mode defaults`);
                  }

                  const modeId = project.data.executionModeId;
                  if (modeId) {
                    try {
                      const modeDoc = await db.collection('users').doc(userId).collection('modes').doc(modeId).get();
                      if (modeDoc.exists) {
                        const modeData = modeDoc.data();
                        console.log(`      ðŸ“‹ Mode loaded: ${modeData.name}`);

                        // Store Mode-level metadata
                        modeMetadata = {
                          modeName: modeData.name || '',
                          category: modeData.category || '',
                          description: modeData.description || '',
                          systemInstruction: modeData.systemInstruction || '',
                          characters: modeData.characters || []
                        };

                        // PRIORITY 1: Use pre-compiled English scenes (from AI)
                        if (modeData.compiledScenes && modeData.compiledScenes.length > 0) {
                          console.log(`      ðŸ¤– Using ${modeData.compiledScenes.length} AI-compiled scenes`);
                          scenes = modeData.compiledScenes;
                          prompts = scenes.map(s => s.englishPrompt);
                        }
                        // PRIORITY 2: Fallback to block titles (rawPrompt removed - Expander handles expansion)
                        else if (modeData.blocks && Array.isArray(modeData.blocks)) {
                          console.log(`      âš ï¸ No compiled scenes, using block titles`);
                          modeData.blocks.forEach((block, blockIdx) => {
                            // Use block title as scene prompt (Expander will expand it later)
                            const sceneTitle = block.title || `Scene ${blockIdx + 1}`;
                            prompts.push(sceneTitle);

                            scenes.push({
                              sceneNumber: scenes.length + 1,
                              englishPrompt: sceneTitle,
                              audioDescription: '',
                              cameraMovement: 'wide',
                              dialogueScript: ''
                            });
                          });
                        }
                        console.log(`      ðŸŽ¬ Total ${prompts.length} prompts ready for execution`);
                      }
                    } catch (modeErr) {
                      console.error(`      âŒ Error loading Mode: ${modeErr.message}`);
                    }
                  }

                  // FALLBACK: Legacy prompts support (if no prompts from Mode)
                  if (prompts.length === 0) {
                    if (variableValues.prompts && Array.isArray(variableValues.prompts)) {
                      prompts = variableValues.prompts;
                    } else if (variableValues.prompt) {
                      prompts = [variableValues.prompt];
                    }
                  }

                  // === EXPANDER INTEGRATION using SHARED LOGIC ===
                  // Check if project has an Expander selected
                  const expanderId = project.data.expanderId;
                  let expanderBlocks = [];
                  let expandedPromptsResult = [];
                  let titlesAndTags = null;

                  if (expanderId) {
                    console.log(`      âš¡ Expander detected: ${expanderId}`);
                    try {
                      // Fetch Expander blocks
                      const expanderDoc = await project.ref.parent.parent.collection('expanders').doc(expanderId).get();
                      if (expanderDoc.exists) {
                        const expanderData = expanderDoc.data();
                        expanderBlocks = expanderData.blocks || [];
                      }
                    } catch (expandErr) {
                      console.error(`      âš ï¸ Error loading Expander:`, expandErr.message);
                    }
                  }

                  // Use SHARED LOGIC for expansion (same as testPromptPipeline)
                  if (scenes.length > 0 || prompts.length > 0) {
                    try {
                      // Build raw scenes from existing data
                      const rawScenes = scenes.length > 0
                        ? scenes.map((s, i) => ({
                            sceneNumber: i + 1,
                            blockTitle: s.blockTitle || `Scene ${i + 1}`,
                            visualPrompt: s.englishPrompt || prompts[i] || '',
                            rawPrompt: s.englishPrompt || prompts[i] || '',
                            audioAmbience: s.audioDescription || '',
                            cameraAngle: s.cameraMovement || 'wide'
                          }))
                        : prompts.map((p, i) => ({
                            sceneNumber: i + 1,
                            blockTitle: `Scene ${i + 1}`,
                            visualPrompt: p,
                            rawPrompt: p,
                            audioAmbience: '',
                            cameraAngle: 'wide'
                          }));

                      console.log(`      ðŸ”§ Using SHARED expandScenesWithTopic() for ${rawScenes.length} scenes...`);

                      // Use SHARED HELPER for per-scene expansion
                      expandedPromptsResult = await expandScenesWithTopic({
                        rawScenes,
                        expanderBlocks,
                        episodeTopic: episodeData?.title || modeMetadata.modeName || 'Video',
                        episodeDesc: episodeData?.description || modeMetadata.description || '',
                        characters: modeMetadata.characters || [],
                        sceneDuration: 8,
                        modeCategory: modeMetadata.category || 'Cinematic',
                        systemInstruction: modeMetadata.systemInstruction || ''
                      });

                      // Update prompts array with expanded versions
                      prompts = expandedPromptsResult.map(p => p.englishPrompt);
                      scenes = expandedPromptsResult;

                      console.log(`      âœ… Expanded ${prompts.length} prompts using SHARED LOGIC`);

                      // Generate Titles and Tags using SHARED HELPER
                      titlesAndTags = await generateTitlesAndTags({
                        episodeTopic: episodeData?.title || modeMetadata.modeName || 'Video',
                        episodeDesc: episodeData?.description || '',
                        modeCategory: modeMetadata.category || 'Entertainment',
                        expandedPrompts: expandedPromptsResult
                      });

                    } catch (expandErr) {
                      console.error(`      âš ï¸ Expansion error (using original prompts):`, expandErr.message);
                    }
                  }

                  // === SAVE TO readyPrompts/ COLLECTION ===
                  const readyPromptData = {
                    prompts: expandedPromptsResult.length > 0 ? expandedPromptsResult : scenes,
                    titles: titlesAndTags?.titles || null,
                    tags: titlesAndTags?.tags || null,
                    episodeId: episodeData?.id || null,
                    episodeTitle: episodeData?.title || null,
                    modeId: modeId || null,
                    modeName: modeMetadata.modeName || null,
                    expanderId: expanderId || null,
                    status: 'ready',
                    createdAt: admin.firestore.FieldValue.serverTimestamp()
                  };

                  const readyPromptRef = await project.ref.collection('readyPrompts').add(readyPromptData);
                  console.log(`      ðŸ“¦ Ready prompt saved: ${readyPromptRef.id}`);

                  // Create Job with COMPLETE scene data
                  await jobRef.set({
                    projectId: project.id,
                    userId: userId,
                    recipeId: modeId || 'CMD_OPEN_BROWSER',
                    type: 'SCHEDULED',
                    status: 'PENDING',
                    variables: variableValues,
                    modeMetadata: modeMetadata, // Mode-level info
                    scenes: scenes, // Complete scene objects
                    prompts: prompts, // Simple prompts for backward compatibility
                    episodeId: episodeData?.id || null, // Link to episode
                    episodeTitle: episodeData?.title || null,
                    createdAt: admin.firestore.FieldValue.serverTimestamp(),
                    scheduledTime: slot.start
                  });

                  // --- ADDED: Write Log for UI Feedback ---
                  await project.ref.collection('logs').add({
                    message: `System: Scheduled Job created for ${slot.start} (${project.data.executionMode || 'Default'})`,
                    timestamp: admin.firestore.FieldValue.serverTimestamp(),
                    platform: 'SYSTEM',
                    type: 'info'
                  });

                  // === MOVE EPISODE TO HISTORY & MARK AS USED ===
                  if (episodeData && episodeData.id) {
                    try {
                      const episodeRef = project.ref.collection('episodes').doc(episodeData.id);
                      
                      // 1. Save to episodeHistory/ collection
                      await project.ref.collection('episodeHistory').add({
                        title: episodeData.title || 'Untitled',
                        description: episodeData.description || '',
                        originalOrder: episodeData.order || 0,
                        originalId: episodeData.id,
                        usedAt: admin.firestore.FieldValue.serverTimestamp(),
                        jobId: jobId,
                        readyPromptId: readyPromptRef.id,
                        generatedPrompts: expandedPromptsResult.length > 0 ? expandedPromptsResult : scenes,
                        titles: titlesAndTags?.titles || null,
                        tags: titlesAndTags?.tags || null,
                        wasSuccessful: true
                      });

                      // 2. Mark Episode as used (or delete - we keep it but mark status)
                      await episodeRef.update({
                        status: 'used',
                        usedAt: admin.firestore.FieldValue.serverTimestamp(),
                        jobId: jobId
                      });

                      console.log(`      ðŸ“š Episode "${episodeData.title}" moved to history`);

                      // === AUTO-REFILL CHECK ===
                      // Check if episodes are running low and auto-refill is enabled
                      const projectData = project.data;
                      if (projectData.autoRefillEnabled) {
                        const threshold = projectData.autoRefillThreshold || 5;
                        const refillCount = projectData.autoRefillCount || 10;
                        const refillPrompt = projectData.autoRefillPrompt || '';

                        const remainingCount = await getRemainingEpisodeCount(project.ref);
                        console.log(`      ðŸ“Š Remaining episodes: ${remainingCount} (threshold: ${threshold})`);

                        if (remainingCount < threshold) {
                          console.log(`      âš ï¸ Episodes running low! Triggering auto-refill...`);

                          // Get history for context
                          const historySnap = await project.ref.collection('episodeHistory')
                            .orderBy('usedAt', 'desc')
                            .limit(20)
                            .get();
                          
                          const historyContext = historySnap.docs.map(d => ({
                            title: d.data().title,
                            description: d.data().description
                          }));

                          // Trigger auto-generate (async, don't wait)
                          autoGenerateEpisodesInternal({
                            projectRef: project.ref,
                            userId: userId,
                            projectId: project.id,
                            count: refillCount,
                            prompt: refillPrompt,
                            historyContext
                          }).then(result => {
                            if (result.success) {
                              console.log(`      âœ… Auto-refill completed: ${result.count} episodes added`);
                            } else {
                              console.error(`      âŒ Auto-refill failed:`, result.error);
                            }
                          }).catch(err => {
                            console.error(`      âŒ Auto-refill error:`, err.message);
                          });
                        }
                      }
                    } catch (historyErr) {
                      console.error(`      âš ï¸ Error moving episode to history:`, historyErr.message);
                    }
                  }

                  console.log(`      ðŸš€ Job Created: ${jobId}`);
                } else {
                  console.log(`      âš ï¸ Job already exists: ${jobId}`);
                }
              }
            }
          }
        } catch (err) {
          console.error(`Error processing user ${userId}:`, err);
        }
      }
    } catch (globalErr) {
      console.error("ðŸ”¥ CRITICAL SCHEDULER ERROR:", globalErr);
    }
  });

// ===== EXPANDER SYSTEM =====

// Function: Expand Prompt
exports.expandPrompt = functions
  .runWith({ secrets: ['OPENAI_API_KEY'], timeoutSeconds: 60 })
  .https.onCall(async (data, context) => {
    const { simplePrompt, blocks } = data;

    if (!simplePrompt || !blocks || blocks.length === 0) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing simplePrompt or blocks');
    }

    try {
      const openai = getOpenAI();

      // Build instruction from blocks
      const blockInstructions = blocks.map((b, i) => `${i + 1}. ${b.name}: ${b.instruction}`).join('\n');

      const systemPrompt = `You are a Premium Prompt Expander for AI video generation (Google Flow / Veo).

Your job is to expand a simple prompt into a detailed, cinematic prompt.

=== ACTIVE BLOCKS (User selected these rules) ===
${blockInstructions}

=== OUTPUT RULES ===
1. Write in English (required for Google Flow)
2. For Thai names, include original in parentheses: "Bas (à¸šà¸²à¸ª)"
3. Include: character descriptions, emotions, lighting, camera angles, ambient sounds
4. Be cinematic and detailed
5. Keep it under 500 words
6. Apply ALL the block instructions above

=== FORMAT ===
Return ONLY the expanded prompt, no explanations.`;

      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Expand this prompt: "${simplePrompt}"` }
        ],
        temperature: 0.8,
        max_tokens: 1000
      });

      const expandedPrompt = response.choices[0].message.content.trim();

      return { expandedPrompt };
    } catch (error) {
      console.error('Error expanding prompt:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// Function: Generate Custom Block via AI Chat
exports.generateBlock = functions
  .runWith({ secrets: ['OPENAI_API_KEY'], timeoutSeconds: 30 })
  .https.onCall(async (data, context) => {
    const { message } = data;

    if (!message) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing message');
    }

    try {
      const openai = getOpenAI();

      const systemPrompt = `You are a Block Generator for a Prompt Expander system.

User will describe what kind of "block" they want. A block is a rule/instruction that modifies how prompts are expanded.

=== YOUR JOB ===
1. Understand what the user wants
2. Generate a block with:
   - name: Short name with emoji (Thai, max 20 chars)
   - type: One of: language, style, lighting, audio, camera, emotion, custom
   - instruction: Clear instruction in English (this will be sent to AI)
   - color: Tailwind color class (bg-red-500, bg-blue-500, etc.)

=== OUTPUT FORMAT (JSON ONLY) ===
{
  "name": "ðŸ›ï¸ à¹‚à¸šà¸£à¸²à¸“",
  "type": "style",
  "instruction": "Use ancient/classical speech patterns. Characters speak formally with traditional expressions.",
  "color": "bg-amber-600"
}

=== EXAMPLES ===
User: "à¸­à¸¢à¸²à¸à¹„à¸”à¹‰à¸à¸¥à¹ˆà¸­à¸‡à¸—à¸µà¹ˆà¸—à¸³à¹ƒà¸«à¹‰à¸•à¸±à¸§à¸¥à¸°à¸„à¸£à¸žà¸¹à¸”à¹à¸šà¸šà¹‚à¸šà¸£à¸²à¸“"
Output: {"name": "ðŸ›ï¸ à¹‚à¸šà¸£à¸²à¸“", "type": "style", "instruction": "Characters speak in ancient/classical Thai style with formal expressions and traditional vocabulary.", "color": "bg-amber-600"}

User: "à¸à¸¥à¹ˆà¸­à¸‡à¸à¸™à¸•à¸"
Output: {"name": "ðŸŒ§ï¸ à¸à¸™à¸•à¸", "type": "lighting", "instruction": "Scene takes place during rain. Include rain sounds, wet surfaces, reflections, and characters getting wet.", "color": "bg-slate-600"}

Return JSON only, no explanation.`;

      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: message }
        ],
        temperature: 0.7,
        max_tokens: 300
      });

      let content = response.choices[0].message.content.trim();
      content = content.replace(/```json/g, '').replace(/```/g, '').trim();

      const block = JSON.parse(content);

      return block;
    } catch (error) {
      console.error('Error generating block:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// Function: Translate Block Instruction to Thai
exports.translateBlockToThai = functions
  .runWith({ secrets: ['OPENAI_API_KEY'], timeoutSeconds: 30 })
  .https.onCall(async (data, context) => {
    const { blockName, instruction } = data;

    if (!blockName || !instruction) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing blockName or instruction');
    }

    try {
      const openai = getOpenAI();

      const systemPrompt = `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸­à¸˜à¸´à¸šà¸²à¸¢ Block à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ à¸žà¸¹à¸”à¹à¸šà¸šà¹€à¸›à¹‡à¸™à¸à¸±à¸™à¹€à¸­à¸‡ à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸žà¸·à¹ˆà¸­à¸™à¸„à¸¸à¸¢à¸à¸±à¸™

=== à¸šà¸—à¸šà¸²à¸—à¸‚à¸­à¸‡à¸„à¸¸à¸“ ===
à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™ "à¸žà¸µà¹ˆà¹à¸™à¸°à¸™à¸³" à¸—à¸µà¹ˆà¸ˆà¸°à¸­à¸˜à¸´à¸šà¸²à¸¢à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸² Block à¸™à¸µà¹‰à¸—à¸³à¸­à¸°à¹„à¸£à¹„à¸”à¹‰à¸šà¹‰à¸²à¸‡
à¸žà¸¹à¸”à¹à¸šà¸šà¹€à¸›à¹‡à¸™à¸à¸±à¸™à¹€à¸­à¸‡ à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¸šà¹‰à¸²à¸™à¹† à¹à¸•à¹ˆà¸¢à¸±à¸‡à¸„à¸‡à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥

=== à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸•à¸­à¸š ===
- à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸”à¹‰à¸§à¸¢ "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š" à¸«à¸£à¸·à¸­ "à¹€à¸®à¹‰à¸„à¸£à¸±à¸š"
- à¹à¸™à¸°à¸™à¸³à¸Šà¸·à¹ˆà¸­ Block à¸à¹ˆà¸­à¸™
- à¸­à¸˜à¸´à¸šà¸²à¸¢à¸§à¹ˆà¸²à¸¡à¸±à¸™à¸—à¸³à¸­à¸°à¹„à¸£à¹„à¸”à¹‰à¹à¸šà¸šà¸ à¸²à¸©à¸²à¸‡à¹ˆà¸²à¸¢à¹†
- à¸–à¹‰à¸²à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸‡à¸²à¸™à¹à¸šà¸šà¹„à¸«à¸™ à¸à¹‡à¹à¸™à¸°à¸™à¸³à¹€à¸žà¸´à¹ˆà¸¡
- à¸ˆà¸šà¸”à¹‰à¸§à¸¢à¸„à¸³à¸Šà¸§à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¹€à¸Šà¹ˆà¸™ "à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸”à¸¹à¸™à¸°à¸„à¸£à¸±à¸š" à¸«à¸£à¸·à¸­ "à¹à¸™à¸°à¸™à¸³à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š"
- à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§ 3-4 à¸›à¸£à¸°à¹‚à¸¢à¸„ à¸žà¸­à¸”à¸µà¹†
- à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¸­à¸±à¸‡à¸à¸¤à¸© à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰à¸„à¸³à¹€à¸—à¸„à¸™à¸´à¸„

=== à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ ===
Block: "ðŸ‡°ðŸ‡· à¸ à¸²à¸©à¸²à¹€à¸à¸²à¸«à¸¥à¸µ"
Instruction: "Translate all dialogues and text into Korean. Ensure appropriate cultural nuances and expressions are maintained."
à¸•à¸­à¸š: "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸™à¸µà¹ˆà¸„à¸·à¸­à¸šà¸¥à¹‡à¸­à¸à¸ à¸²à¸©à¸²à¹€à¸à¸²à¸«à¸¥à¸µà¸„à¸£à¸±à¸š à¸–à¹‰à¸²à¸„à¸¸à¸“à¹ƒà¸ªà¹ˆà¸šà¸¥à¹‡à¸­à¸à¸™à¸µà¹‰à¹€à¸‚à¹‰à¸²à¹„à¸› à¸§à¸´à¸”à¸µà¹‚à¸­à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸ˆà¸°à¸žà¸¹à¸”à¸ à¸²à¸©à¸²à¹€à¸à¸²à¸«à¸¥à¸µà¹„à¸”à¹‰à¹€à¸¥à¸¢ à¹à¸–à¸¡à¸¢à¸±à¸‡à¸„à¸³à¸™à¸¶à¸‡à¸–à¸¶à¸‡à¸§à¸±à¸’à¸™à¸˜à¸£à¸£à¸¡à¹€à¸à¸²à¸«à¸¥à¸µà¸”à¹‰à¸§à¸¢à¸™à¸°à¸„à¸£à¸±à¸š à¹à¸™à¸°à¸™à¸³à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šà¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸—à¸³à¸„à¸­à¸™à¹€à¸—à¸™à¸•à¹Œà¹ƒà¸«à¹‰à¸„à¸™à¹€à¸à¸²à¸«à¸¥à¸µà¸”à¸¹"

Block: "ðŸŽ¬ à¸‹à¸µà¸™à¸µà¸¡à¸²à¸•à¸´à¸"
Instruction: "Apply cinematic color grading with dramatic lighting. Use wide shots and smooth camera movements."
à¸•à¸­à¸š: "à¹€à¸®à¹‰à¸„à¸£à¸±à¸š à¸šà¸¥à¹‡à¸­à¸à¸™à¸µà¹‰à¸Šà¸·à¹ˆà¸­à¸‹à¸µà¸™à¸µà¸¡à¸²à¸•à¸´à¸à¸„à¸£à¸±à¸š à¹ƒà¸ªà¹ˆà¸›à¸¸à¹Šà¸š à¸§à¸´à¸”à¸µà¹‚à¸­à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸ˆà¸°à¸”à¸¹à¹€à¸«à¸¡à¸·à¸­à¸™à¸«à¸™à¸±à¸‡à¸®à¸­à¸¥à¸¥à¸µà¸§à¸¹à¸”à¹€à¸¥à¸¢ à¸¡à¸µà¹à¸ªà¸‡à¸ªà¸µà¸ªà¸§à¸¢à¹† à¸¡à¸¸à¸¡à¸à¸¥à¹‰à¸­à¸‡à¸à¸§à¹‰à¸²à¸‡à¹† à¸”à¸¹à¸­à¸¥à¸±à¸‡à¸à¸²à¸£à¸¡à¸²à¸ à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸„à¸™à¸—à¸µà¹ˆà¸­à¸¢à¸²à¸à¹ƒà¸«à¹‰à¸‡à¸²à¸™à¸”à¸¹à¸žà¸£à¸µà¹€à¸¡à¸µà¸¢à¸¡à¸„à¸£à¸±à¸š"

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µ JSON`;

      const response = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Block: "${blockName}"\nInstruction: "${instruction}"` }
        ],
        temperature: 0.7,
        max_tokens: 200
      });

      const thaiDescription = response.choices[0].message.content.trim();

      return { thaiDescription };
    } catch (error) {
      console.error('Error translating block:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// ============================================
// CONTENT PIPELINE FUNCTIONS
// ============================================

// Function: Generate Episodes from Topic (AI Episode Director)
exports.generateEpisodes = functions
  .runWith({ timeoutSeconds: 60, memory: '512MB' })
  .https.onCall(async (data, context) => {
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }

    const { prompt } = data;
    if (!prompt) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing prompt');
    }

    try {
      const openai = getOpenAI();
      const response = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `You are an AI Episode Director. Create an episode list for video content.
            
            Rules:
            - Generate 5-15 episodes based on the user's topic
            - Each episode should have a clear, engaging title
            - Include a brief description (1-2 sentences)
            - Make episodes progressive (build on each other)
            - Titles should be catchy and YouTube-friendly
            
            Output JSON format:
            {
              "episodes": [
                { "title": "Episode Title", "description": "Brief description" },
                ...
              ]
            }
            
            IMPORTANT: Output valid JSON only, no markdown.`
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.8,
        max_tokens: 2000
      });

      let content = response.choices[0].message.content;
      content = content.replace(/```json/g, '').replace(/```/g, '').trim();

      const result = JSON.parse(content);
      return { episodes: result.episodes };
    } catch (error) {
      console.error('Error generating episodes:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// Function: Expand Episode to Full Prompts (Episode + Mode Template + Expander)
exports.expandEpisodeToPrompts = functions
  .runWith({ timeoutSeconds: 120, memory: '1GB' })
  .https.onCall(async (data, context) => {
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }

    const userId = context.auth.uid;
    const { projectId, episodeId } = data;

    if (!projectId || !episodeId) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing projectId or episodeId');
    }

    try {
      const db = admin.firestore();

      // 1. Get Episode
      const episodeDoc = await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .collection('episodes').doc(episodeId)
        .get();

      if (!episodeDoc.exists) {
        throw new functions.https.HttpsError('not-found', 'Episode not found');
      }
      const episode = episodeDoc.data();

      // 2. Get Project (to get modeId and expanderId)
      const projectDoc = await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .get();

      if (!projectDoc.exists) {
        throw new functions.https.HttpsError('not-found', 'Project not found');
      }
      const project = projectDoc.data();

      // 3. Get Mode Template
      let modeBlocks = [];
      if (project.executionModeId) {
        const modeDoc = await db
          .collection('users').doc(userId)
          .collection('modes').doc(project.executionModeId)
          .get();

        if (modeDoc.exists) {
          const mode = modeDoc.data();
          modeBlocks = mode.blocks || [];
        }
      }

      // 4. Get Expander Blocks
      let expanderBlocks = [];
      if (project.expanderId) {
        // Check user's expanders first
        let expanderDoc = await db
          .collection('users').doc(userId)
          .collection('expanders').doc(project.expanderId)
          .get();

        // If not found, check purchased expanders
        if (!expanderDoc.exists) {
          expanderDoc = await db
            .collection('users').doc(userId)
            .collection('purchasedExpanders').doc(project.expanderId)
            .get();
        }

        if (expanderDoc.exists) {
          const expander = expanderDoc.data();
          expanderBlocks = expander.blocks || [];
        }
      }

      // 5. Build Scene Templates (replace [TOPIC] with episode title)
      const sceneTemplates = modeBlocks.map((block, idx) => {
        const evolution = block.evolution || [];
        return evolution.map((step, stepIdx) => {
          // Replace [TOPIC] placeholder with actual episode title
          let template = step.rawPrompt || '';
          template = template.replace(/\[TOPIC\]/gi, episode.title);
          return {
            sceneNumber: idx + 1,
            stepNumber: stepIdx + 1,
            simplePrompt: template || `${episode.title} - à¸‰à¸²à¸ ${idx + 1}`,
            percentage: step.stepPercentage || 0
          };
        });
      }).flat();

      // 6. Build Expander Block Instructions (same format as expandPrompt function)
      const blockInstructions = expanderBlocks.map((b, i) =>
        `${i + 1}. ${b.name}: ${b.instruction || b.description || ''}`
      ).join('\n');

      // 7. Expand EACH scene using Expander (same logic as expandPrompt)
      const openai = getOpenAI();
      const expandedPrompts = [];

      for (let i = 0; i < sceneTemplates.length; i++) {
        const scene = sceneTemplates[i];

        const systemPrompt = `You are a Premium Prompt Expander for AI video generation (Google Flow / Veo).

Your job is to expand a simple prompt into a detailed, cinematic prompt.

=== ACTIVE BLOCKS (User selected these rules) ===
${blockInstructions || 'Standard cinematic style'}

=== OUTPUT RULES ===
1. Write in English (required for Google Flow)
2. For Thai names, include original in parentheses: "Bas (à¸šà¸²à¸ª)"
3. Include: character descriptions, emotions, lighting, camera angles, ambient sounds
4. Be cinematic and detailed
5. Keep it under 500 words
6. Apply ALL the block instructions above

=== FORMAT ===
Return ONLY the expanded prompt, no explanations.`;

        const response = await openai.chat.completions.create({
          model: 'gpt-4o',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: `Expand this prompt: "${scene.simplePrompt}"` }
          ],
          temperature: 0.8,
          max_tokens: 1000
        });

        const expandedPrompt = response.choices[0].message.content.trim();

        expandedPrompts.push({
          sceneNumber: scene.sceneNumber,
          stepNumber: scene.stepNumber,
          originalPrompt: scene.simplePrompt,
          prompt: expandedPrompt,
          percentage: scene.percentage
        });
      }

      // 8. Generate title and caption
      const titleResponse = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: 'Generate a catchy video title and social media caption in Thai. Output JSON: {"title": "...", "caption": "..."}' },
          { role: 'user', content: `Topic: ${episode.title}\nDescription: ${episode.description || ''}` }
        ],
        temperature: 0.7,
        max_tokens: 200
      });

      let titleContent = titleResponse.choices[0].message.content;
      titleContent = titleContent.replace(/```json/g, '').replace(/```/g, '').trim();
      const titleData = JSON.parse(titleContent);

      const result = {
        prompts: expandedPrompts,
        title: titleData.title,
        caption: titleData.caption
      };

      // 8. Mark Episode as Completed
      await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .collection('episodes').doc(episodeId)
        .update({
          status: 'completed',
          completedAt: admin.firestore.FieldValue.serverTimestamp(),
          generatedPrompts: result.prompts
        });

      return result;
    } catch (error) {
      console.error('Error expanding episode:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// ============================================
// TEST PROMPT PIPELINE
// ============================================

// Function: Test full prompt pipeline (Mode + Expander â†’ Full Prompts + Titles + Tags)
exports.testPromptPipeline = functions
  .runWith({ secrets: ['OPENAI_API_KEY'], timeoutSeconds: 300, memory: '1GB' })
  .https.onCall(async (data, context) => {
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }

    const userId = context.auth.uid;
    const { projectId, sceneDuration: inputSceneDuration } = data;

    if (!projectId) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing projectId');
    }

    try {
      const db = admin.firestore();
      const openai = getOpenAI();

      // 1. Get Project
      const projectDoc = await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .get();

      if (!projectDoc.exists) {
        throw new functions.https.HttpsError('not-found', 'Project not found');
      }
      const project = projectDoc.data();

      // 1.5. Get sceneDuration from slots or use input/default
      let sceneDuration = inputSceneDuration || 8; // default 8 seconds
      const slotsSnap = await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .collection('slots').limit(1).get();

      if (!slotsSnap.empty) {
        const slotData = slotsSnap.docs[0].data();
        sceneDuration = slotData.sceneDuration || sceneDuration;
      }
      console.log(`ðŸ“ Scene Duration: ${sceneDuration} seconds`);

      // 2. Get Mode
      const modeId = project.executionModeId;
      if (!modeId) {
        throw new functions.https.HttpsError('failed-precondition', 'No Mode selected for this project');
      }

      const modeDoc = await db
        .collection('users').doc(userId)
        .collection('modes').doc(modeId)
        .get();

      if (!modeDoc.exists) {
        throw new functions.https.HttpsError('not-found', 'Mode not found');
      }
      const modeData = modeDoc.data();

      // 3. Get Expander (optional)
      let expanderBlocks = [];
      const expanderId = project.expanderId;
      if (expanderId) {
        const expanderDoc = await db
          .collection('users').doc(userId)
          .collection('expanders').doc(expanderId)
          .get();

        if (expanderDoc.exists) {
          const expanderData = expanderDoc.data();
          expanderBlocks = expanderData.blocks || [];
        }
      }

      // 3.5. Get Episode from Content Queue using SHARED HELPER
      // Read episode selection mode from project settings (default: sequential)
      const episodeSelectionMode = project.episodeSelection || 'sequential';
      const projectRef = db.collection('users').doc(userId).collection('projects').doc(projectId);
      
      // Use SHARED getNextEpisode helper (same logic as scheduleJobs)
      const episodeData = await getNextEpisode(projectRef, episodeSelectionMode);

      if (episodeData) {
        console.log(`ðŸ“º Episode Topic: "${episodeData.title}" (mode: ${episodeSelectionMode})`);
        // NOTE: We do NOT change episode status for Test - it stays 'pending'
      } else {
        console.log(`âš ï¸ No pending episodes, using Mode name as topic`);
      }

      // 4. Extract Scenes from Mode using SHARED HELPER
      const rawScenes = extractRawScenesFromMode(modeData);
      const characters = modeData.characters || [];

      if (rawScenes.length === 0) {
        throw new functions.https.HttpsError('failed-precondition', 'Mode has no scenes. Add evolution steps to blocks.');
      }

      // Build Episode context
      const episodeTopic = episodeData?.title || modeData.name || 'Untitled Video';
      const episodeDesc = episodeData?.description || modeData.description || '';

      console.log(`ðŸ“‹ testPromptPipeline: Using SHARED LOGIC (per-scene expansion)`);
      console.log(`   Episode Topic: "${episodeTopic}"`);
      console.log(`   Raw Scenes: ${rawScenes.length}`);
      console.log(`   Expander Blocks: ${expanderBlocks.length}`);

      // 5. Use SHARED HELPER for per-scene expansion (same as Production)
      const expandedPrompts = await expandScenesWithTopic({
        rawScenes,
        expanderBlocks,
        episodeTopic,
        episodeDesc,
        characters,
        sceneDuration,
        modeCategory: modeData.category,
        systemInstruction: modeData.systemInstruction
      });

      // 6. Generate Titles and Tags using SHARED HELPER
      const titlesAndTags = await generateTitlesAndTags({
        episodeTopic,
        episodeDesc,
        modeCategory: modeData.category,
        expandedPrompts
      });

      // 7. Combine results
      const result = {
        prompts: expandedPrompts,
        titles: titlesAndTags.titles,
        tags: titlesAndTags.tags
      };

      // 7. Save Test Result to testLogs/ collection (separate from Project, with TTL)
      const expiresAt = new Date();
      expiresAt.setDate(expiresAt.getDate() + 7); // TTL: 7 days

      const testLogData = {
        prompts: result.prompts,
        titles: result.titles,
        tags: result.tags,
        episodeId: episodeData?.id || null,
        episodeTitle: episodeData?.title || null,
        modeId: modeId,
        modeName: modeData.name || 'Unknown',
        expanderId: expanderId || null,
        expanderBlockCount: expanderBlocks.length,
        sceneCount: rawScenes.length,
        sceneDuration: sceneDuration,
        totalDuration: rawScenes.length * sceneDuration,
        createdAt: admin.firestore.FieldValue.serverTimestamp(),
        expiresAt: admin.firestore.Timestamp.fromDate(expiresAt) // TTL field for cleanup
      };

      // Save to testLogs/ subcollection
      const testLogRef = await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .collection('testLogs')
        .add(testLogData);

      console.log(`ðŸ“ Test log saved: ${testLogRef.id} (expires: ${expiresAt.toISOString()})`);

      // Also update lastPromptTest on Project for quick access
      await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .update({
          lastPromptTest: {
            ...result,
            testLogId: testLogRef.id,
            testedAt: admin.firestore.FieldValue.serverTimestamp(),
            modeId: modeId,
            modeName: modeData.name || 'Unknown',
            expanderId: expanderId || null,
            sceneCount: rawScenes.length,
            episodeId: episodeData?.id || null,
            episodeTitle: episodeData?.title || null
          }
        });

      // 8. Log the test with detailed info
      await db
        .collection('users').doc(userId)
        .collection('projects').doc(projectId)
        .collection('logs').add({
          message: `âœ… Prompt Test: "${episodeTopic}" - Generated ${result.prompts?.length || 0} prompts`,
          timestamp: admin.firestore.FieldValue.serverTimestamp(),
          platform: 'SYSTEM',
          type: 'test',
          testLogId: testLogRef.id,
          sceneCount: rawScenes.length,
          sceneDuration: sceneDuration,
          totalLength: rawScenes.length * sceneDuration,
          topic: episodeTopic,
          modeId: modeId,
          modeName: modeData.name || 'Unknown'
        });

      console.log(`âœ… Test Pipeline completed: ${result.prompts?.length || 0} prompts for project ${projectId}`);

      return {
        success: true,
        ...result,
        modeInfo: {
          id: modeId,
          name: modeData.name,
          sceneCount: rawScenes.length
        },
        expanderInfo: expanderId ? {
          id: expanderId,
          blockCount: expanderBlocks.length
        } : null
      };

    } catch (error) {
      console.error('Test Pipeline Error:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// Function: Text-to-Speech using Google Cloud TTS (Thai voice)
exports.textToSpeechThai = functions
  .runWith({ timeoutSeconds: 30, memory: '256MB' })
  .https.onCall(async (data, context) => {
    const { text } = data;

    if (!text) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing text');
    }

    try {
      const client = new TextToSpeechClient();

      const request = {
        input: { text: text },
        voice: {
          languageCode: 'th-TH',
          name: 'th-TH-Chirp3-HD-Charon', // Thai male voice - Chirp HD (natural)
          ssmlGender: 'MALE'
        },
        audioConfig: {
          audioEncoding: 'MP3',
          pitch: 0,
          speakingRate: 1.0
        }
      };

      const [response] = await client.synthesizeSpeech(request);

      // Return base64 encoded audio
      const audioBase64 = response.audioContent.toString('base64');

      return {
        audioBase64,
        mimeType: 'audio/mpeg'
      };
    } catch (error) {
      console.error('TTS Error:', error);
      throw new functions.https.HttpsError('internal', error.message);
    }
  });

// ============================================
// AUTO-REFILL SYSTEM
// ============================================

/**
 * Auto-Generate Episodes when queue is running low
 * Called by scheduleJobs or manually via callable
 */
async function autoGenerateEpisodesInternal(params) {
  const { projectRef, userId, projectId, count = 10, prompt = '', historyContext = [] } = params;
  
  const openai = getOpenAI();
  const db = admin.firestore();

  // Build context from history
  const historyTitles = historyContext.length > 0
    ? historyContext.map((h, i) => `${i + 1}. ${h.title}`).join('\n')
    : 'No previous episodes';

  const systemPrompt = `You are an AI Episode Director for video content creation.

=== PREVIOUS EPISODES (for context/style) ===
${historyTitles}

=== USER INSTRUCTION ===
${prompt || 'Create engaging video episode topics that follow the established theme/style.'}

=== TASK ===
Generate ${count} NEW episode ideas that:
1. Follow the same theme/style as previous episodes (if any)
2. Are unique and not repetitive
3. Have catchy, engaging titles
4. Include brief descriptions

=== OUTPUT FORMAT (JSON) ===
{
  "episodes": [
    { "title": "Episode Title", "description": "Brief 1-2 sentence description" }
  ]
}

IMPORTANT: Output valid JSON only, no markdown.`;

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: `Generate ${count} new episodes` }
      ],
      temperature: 0.8,
      max_tokens: 2000
    });

    let content = response.choices[0].message.content.trim();
    content = content.replace(/```json/g, '').replace(/```/g, '').trim();

    const result = JSON.parse(content);
    const episodes = result.episodes || [];

    if (episodes.length === 0) {
      console.log(`âš ï¸ AI returned no episodes`);
      return { success: false, count: 0 };
    }

    // Get last order number
    const lastEpisodeSnap = await projectRef.collection('episodes')
      .orderBy('order', 'desc')
      .limit(1)
      .get();
    
    let lastOrder = 0;
    if (!lastEpisodeSnap.empty) {
      lastOrder = lastEpisodeSnap.docs[0].data().order || 0;
    }

    // Batch write new episodes
    const batch = db.batch();
    episodes.forEach((ep, i) => {
      const ref = projectRef.collection('episodes').doc();
      batch.set(ref, {
        title: ep.title,
        description: ep.description || '',
        order: lastOrder + i + 1,
        status: 'pending',
        createdAt: admin.firestore.FieldValue.serverTimestamp(),
        createdBy: 'auto-refill'
      });
    });

    await batch.commit();

    // Log the auto-generation
    await projectRef.collection('logs').add({
      message: `ðŸ¤– Auto-Refill: Generated ${episodes.length} new episodes`,
      timestamp: admin.firestore.FieldValue.serverTimestamp(),
      platform: 'SYSTEM',
      type: 'auto-refill',
      episodeCount: episodes.length
    });

    console.log(`âœ… Auto-generated ${episodes.length} new episodes for project ${projectId}`);

    return { success: true, count: episodes.length, episodes };

  } catch (error) {
    console.error('Auto-generate episodes error:', error);
    return { success: false, error: error.message };
  }
}

// ============================================
// CLEANUP FUNCTION: Delete expired testLogs (TTL 7 days)
// Runs daily at 2:00 AM UTC
// ============================================
exports.cleanupExpiredTestLogs = functions.pubsub.schedule('0 2 * * *')
  .timeZone('UTC')
  .onRun(async (context) => {
    const db = admin.firestore();
    const now = admin.firestore.Timestamp.now();
    
    console.log('ðŸ§¹ Starting cleanup of expired testLogs...');
    
    try {
      // Get all users
      const usersSnap = await db.collection('users').get();
      let totalDeleted = 0;

      for (const userDoc of usersSnap.docs) {
        const projectsSnap = await userDoc.ref.collection('projects').get();
        
        for (const projectDoc of projectsSnap.docs) {
          // Find expired testLogs
          const expiredLogs = await projectDoc.ref.collection('testLogs')
            .where('expiresAt', '<', now)
            .get();
          
          if (!expiredLogs.empty) {
            const batch = db.batch();
            expiredLogs.docs.forEach(doc => batch.delete(doc.ref));
            await batch.commit();
            totalDeleted += expiredLogs.size;
            console.log(`   Deleted ${expiredLogs.size} expired testLogs from project ${projectDoc.id}`);
          }
        }
      }
      
      console.log(`âœ… Cleanup complete: Deleted ${totalDeleted} expired testLogs`);
    } catch (error) {
      console.error('âŒ Cleanup error:', error);
    }
  });

// ============================================
// CLEANUP FUNCTION: Delete old episodeHistory (older than 30 days)
// Runs weekly on Sunday at 3:00 AM UTC
// ============================================
exports.cleanupOldEpisodeHistory = functions.pubsub.schedule('0 3 * * 0')
  .timeZone('UTC')
  .onRun(async (context) => {
    const db = admin.firestore();
    const thirtyDaysAgo = new Date();
    thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
    const cutoffTimestamp = admin.firestore.Timestamp.fromDate(thirtyDaysAgo);
    
    console.log('ðŸ§¹ Starting cleanup of old episodeHistory (>30 days)...');
    
    try {
      const usersSnap = await db.collection('users').get();
      let totalDeleted = 0;

      for (const userDoc of usersSnap.docs) {
        const projectsSnap = await userDoc.ref.collection('projects').get();
        
        for (const projectDoc of projectsSnap.docs) {
          // Find old history entries
          const oldHistory = await projectDoc.ref.collection('episodeHistory')
            .where('usedAt', '<', cutoffTimestamp)
            .get();
          
          if (!oldHistory.empty) {
            const batch = db.batch();
            oldHistory.docs.forEach(doc => batch.delete(doc.ref));
            await batch.commit();
            totalDeleted += oldHistory.size;
            console.log(`   Deleted ${oldHistory.size} old history entries from project ${projectDoc.id}`);
          }
        }
      }
      
      console.log(`âœ… History cleanup complete: Deleted ${totalDeleted} old entries`);
    } catch (error) {
      console.error('âŒ History cleanup error:', error);
    }
  });

// Callable function for manual trigger
exports.autoGenerateEpisodes = functions
  .runWith({ timeoutSeconds: 60, memory: '512MB' })
  .https.onCall(async (data, context) => {
    if (!context.auth) {
      throw new functions.https.HttpsError('unauthenticated', 'User must be logged in');
    }

    const userId = context.auth.uid;
    const { projectId, count = 10, prompt = '' } = data;

    if (!projectId) {
      throw new functions.https.HttpsError('invalid-argument', 'Missing projectId');
    }

    const db = admin.firestore();
    const projectRef = db.collection('users').doc(userId).collection('projects').doc(projectId);

    // Check project exists
    const projectDoc = await projectRef.get();
    if (!projectDoc.exists) {
      throw new functions.https.HttpsError('not-found', 'Project not found');
    }

    // Get history for context
    const historySnap = await projectRef.collection('episodeHistory')
      .orderBy('usedAt', 'desc')
      .limit(20)
      .get();
    
    const historyContext = historySnap.docs.map(d => ({
      title: d.data().title,
      description: d.data().description
    }));

    const result = await autoGenerateEpisodesInternal({
      projectRef,
      userId,
      projectId,
      count,
      prompt,
      historyContext
    });

    if (!result.success) {
      throw new functions.https.HttpsError('internal', result.error || 'Failed to generate episodes');
    }

    return result;
  });

